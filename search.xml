<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[keras模型拼接]]></title>
    <url>%2F2018%2F12%2F25%2Fkeras%E6%A8%A1%E5%9E%8B%E6%8B%BC%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[在模型测试过程中，如何让两个模型中间层的输入输出拼在一起呢？ 首先，加载训练好的模型后，我们可以用下面的方式获取模型的中间层输出：12model = load_model(&quot;model1.h5&quot;)First_model = Model(inputs=model.input, outputs=model.layers[7].output)#表示获取模型第7层的输出 然后如何把第7层的输出，作为下一个模型中间层的输入呢？用下面的方法是不可以的：12model2 = load_model(&quot;model2.h5&quot;)second_model = Model(inputs=model2.layers[8].input, outputs=model2.layers[-1].output) 这样会得到类似下面的错误：1RuntimeError: Graph disconnected: cannot obtain value for tensor Tensor(&quot;conv2d_1_input:0&quot;, shape=(?, 144, 144, 3), dtype=float32) at layer &quot;conv2d_1_input&quot;. The following previous layers were accessed without issue: [] 解决办法是声明一个新的Input Layer,用下面的方式拼接：12345second_input = Input(model.layers[8].input_shape[1:])second_model = second_inputfor layer in model.layers[8:]: second_model = layer(second_model)second_model = Model(inputs=second_input, outputs=second_model) 由此，便完成了模型的拼接！]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建博客时候问题小记]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E6%97%B6%E5%80%99%E9%97%AE%E9%A2%98%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[摘要：汇总搭建博客遇见的几个问题 nothing added to commit but untracked files present1234567891011121314$ git commit -m &quot;first commit&quot;On branch masterUntracked files: .gitignore _config.yml git git.pub package-lock.json package.json scaffolds/ source/ themes/nothing added to commit but untracked files present 这个错误原因有两个： 已经存在的项目？ 没有把需要提交的文件加载进来，所以需要用1git add （文件名） fatal: remote origin already exists.1fatal: remote origin already exists. 用到的解决办法： 删除远程仓库，再添加远程仓库 123$git remote rm origin$git remote add origin git@github.com:wufans/wufans.github.io.git 修改git的config文件的内容。 1$vi .git/config 删除[remote “origin”] github rejected123456To github.com:wufans/wufans.github.io.git ! [rejected] master -&gt; master (non-fast-forward) &apos;git@github.com:wufans/wufans.github.io.git&apos;hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: &apos;git pull ...&apos;) before pushing again. 这个方法就是因为本地仓库和github上面仓库的内容有冲突导致的我用的解决办法是删除了原来的repository，重新建立了一个仓库，问题解决。 创建流量统计功能的方法参考博客 附加功能的添加参考博客 解决公式显示不正常的问题参考博客 hexo设置侧边栏头像编辑站点的 _config.yml，新增字段 avatar， 值设置成头像的链接地址。 其中，头像的链接地址可以是： 完整的互联网 URL，例如：https://avatars1.githubusercontent.com/u/32269?v=3&amp;s=460 站点内的地址，例如： /uploads/avatar.jpg 需要将你的头像图片放置在 站点的 source/uploads/（可能需要新建uploads目录）/images/avatar.jpg 需要将你的头像图片放置在 主题的 source/images/ 目录下。 hexo部署失败，不能连接github的解决一直在解决这个问题，修改了本地文件的几个配置之后，突然发现生成的博客不能直接push到github上了，显示错误但是用12hexo generatehexo server 部署到本地的时候是没有问题的。然后用1ssh -T git@gihub.com 测试连接也出现了1ssh_exchange_identification: read:Connection reset by peer 和1Connection reset by 192.30.253.112 port 22 这样的错误尝试了以下解决办法： 因为前几次修改了hosts文件解决github不能加载CSS的问题，让电脑解析github的域名时用的是自定义的IP，所以可能有这个原因，因此在hosts里面注释掉了修改的部分，然后刷新DNS缓存123ipconfig /flushdns#这里还遇到了ipconfig和ping不是一个命令的错误，需要配置环境变量path#%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem 最后发现没用。 删除了github上面的ssh配置，重新配置了github服务器端与本地的ssh秘钥，然后再使用1ssh -T git@gihub.com 结果能连上了，但是再用1hexo deploy 之后，又报了刚才的错误，而且再测试与github上面的连接居然也出错了~ 俗话说，重启治百病，于是重启了一下————是的，没用 用网上的解决办法，可能是网络防火墙设置的原因，用手机给电脑开热点再测试连接，结果也没用最后打算第二天重新部署博客了，然后奇迹发生了，起床之后再测试链接，work~ Github不能访问、不能正常加载CSS的解决修改了windows的hosts文件之后，经常会出现github访问异常，页面的CSS样式无法加载等的情况。解决办法给hosts文件增加github的CDN fastly.net,跳过域名解析，直接通过IP访问github。在hosts文件下增加一行：1185.31.17.184 github.global.ssl.fastly.net 问题 使用1hexo deploy 部署博客时，出现下列错误：123456789101112131415161718fatal: TaskCanceledException encountered. ▒▒ȡ▒▒һ▒▒▒▒▒▒bash: /dev/tty: No such device or addresserror: failed to execute prompt script (exit code 1)fatal: could not read Username for &apos;https://github.com&apos;: No errorFATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: fatal: TaskCanceledException encountered. ��ȡ��һ������bash: /dev/tty: No such device or addresserror: failed to execute prompt script (exit code 1)fatal: could not read Username for &apos;https://github.com&apos;: No error at ChildProcess.&lt;anonymous&gt; (D:\blog\GIT\hexo\node_modules\hexo-util\lib\spawn.js:37:17) at emitTwo (events.js:125:13) at ChildProcess.emit (events.js:213:7) at ChildProcess.cp.emit (D:\blog\GIT\hexo\node_modules\cross-spawn\lib\enoent.js:40:29) at maybeClose (internal/child_process.js:927:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:211:5) 解决 如果开启了本地预览，先关闭然后用1hexo clean 清空缓存，再重新生成静态文件并部署，问题解决~ 另外用了上面的方法之后还出现了这个问题的话，重启一下电脑~~ 添加版权声明添加版权声明 在Github上，Next主题的issues上有设置 Creative Commons 协议，这个就是设置版权声明，但是配置了以后图标比较小，没有文字说明（就是没逼格），而且还会出现在它不该出现的地方。 新建 passage-end-tag.swig 文件在路径\themes\next\layout_macro中添加passage-end-tag.swig文件，其内容为： 12345678910111213&#123;% if theme.passage_end_tag.enabled %&#125;&lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;------ 本文结束 ------&lt;/div&gt;&lt;br/&gt;&lt;div style=&quot;border: 1px solid black&quot;&gt;&lt;div style=&quot;margin-left:10px&quot;&gt;&lt;span style=&quot;font-weight:blod&quot;&gt;版权声明&lt;/span&gt;&lt;img src=&quot;http://creativecommons.org/images/deed/logo_deed.gif&quot;&gt;&lt;a href=&quot;http://wufan.site/&quot; style=&quot;color:#258FC6&quot;&gt;Fan Wu&apos;s Blog&lt;/a&gt; by &lt;a href=&quot;http://wufan.site/&quot; style=&quot;color:#258FC6&quot;&gt;Fan Wu&lt;/a&gt; is licensed under a &lt;a href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot; style=&quot;color:#258FC6&quot;&gt;Creative Commons BY-NC-ND 4.0 International License&lt;/a&gt;.&lt;br/&gt;由&lt;a href=&quot;http://wufan.site/&quot; style=&quot;color:#258FC6&quot;&gt;Fan Wu&lt;/a&gt;创作并维护的&lt;a href=&quot;http://wufan.site/&quot; style=&quot;color:#258FC6&quot;&gt;Fan Wu&apos;s Blog&lt;/a&gt;博客采用&lt;a href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot; style=&quot;color:#258FC6&quot;&gt;创作共用保留署名-非商业-禁止演绎4.0国际许可证&lt;/a&gt;。&lt;br/&gt;本文首发于&lt;a href=&quot;http://wufan.site/&quot; style=&quot;color:#258FC6&quot;&gt;Fan Wu&apos;s Blog&lt;/a&gt; 博客（ &lt;a href=&quot;http://wufan.site/&quot; style=&quot;color:#258FC6&quot;&gt;http://wufan.site/&lt;/a&gt; ），版权所有，侵权必究。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&#123;% endif %&#125; 如果觉得上面的样式不好看，也可以引用下面的内容：1234567891011121314151617&#123;% if theme.passage_end_tag.enabled %&#125;&lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;-------------本文结束&lt;i class=&quot;fa fa-heart&quot;&gt;&lt;/i&gt;感谢阅读-------------&lt;/div&gt;&lt;ul class=&quot;post-copyright&quot;&gt; &lt;li class=&quot;post-copyright-author&quot;&gt; &lt;strong&gt;本文作者:&lt;/strong&gt;&#123;&#123; theme.author &#125;&#125; &lt;/li&gt; &lt;li class=&quot;post-copyright-link&quot;&gt; &lt;strong&gt;本文链接:&lt;/strong&gt; &lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.path &#125;&#125;&lt;/a&gt; &lt;/li&gt; &lt;li class=&quot;post-copyright-license&quot;&gt; &lt;strong&gt;许可协议:&lt;/strong&gt; 除特殊声明外，本站博文均采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-sa/3.0/cn/&quot; rel=&quot;external nofollow&quot; target=&quot;_blank&quot;&gt;CC BY-NC-SA 4.0 CN&lt;/a&gt; 许可协议，转载请注明出处！ &lt;/li&gt;&lt;/ul&gt;&#123;% endif %&#125; 修改 post.swig 文件在\themes\next\layout_macro\post.swig中，post-body之后，post-footer之前添加如下代码：12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;passage-end-tag.swig&apos; %&#125; &#123;% endif %&#125;&lt;/div&gt; 在主题配置文件中添加字段在主题配置文件”_config.yml”中添加以下字段开启此功能： 123#文章末尾添加“本文结束”标记passage_end_tag: enabled: true 完成以上设置之后，在每篇文章之后都会添加“版权声明”标记。 添加动画效果背景动画基于canvas，添加到博客上也比较简单，在\themes\next\layout_layout.swig的上面添加123&#123;% if theme.canvas_nest %&#125; &lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 在\themes\next_config.yml中添加以下字段开启此功能：1234# background settings# add canvas-nest effect# see detail from https://github.com/hustcc/canvas-nest.jscanvas_nest: true 添加完了，发现博客背景是白色，会遮住动画，只留下两边一点点的位置看到动画效果，这时候可以去设置一下背景颜色，在\themes\next\source\css_schemes\Pisces_layout.styl中，把.content-wrap中的background修改为none。 这时候如果用手机打开，也能看到动画效果，但是带来的体验不好，显得页面比较乱，这是可以把.content-wrap的+mobile()中的background修改为white，这样手机端的体验就好很多，却又不影响电脑端的炫酷动画。 解决博客浏览统计功能突然失效的方法（hexo-theme-next-busuanzi_count）说明我这里是使用的hexo-theme-next主题，主题版本为：3.8.0(更新于10-31日) 原因分析由于定位到是不蒜子统计功能突然有问题了，所以前往不蒜子官网进行查看，发现官网有一段很重要的提示：“因七牛强制过期『dn-lbstatics.qbox.me』域名，与客服沟通无果，只能更换域名到『busuanzi.ibruce.info』！”所以定位到问题，原来是不蒜子使用的七牛的域名被强制过期。需要把 dn-lbstatics.qbox.me 域名更换为 busuanzi.ibruce.info 解决方案hexo-theme-next主题中使用了dn-lbstatics.qbox.me域名的文件位置为： 1themes\next\layout\_third-party\analytics\busuanzi-counter.swig 修改busuanzi-counter.swig 找到如下代码：1&lt;script async src=&quot;https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 修改为：1&lt;script async src=&quot;https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 重新预览，即可看到不蒜子统计功能已经生效原文 恢复你的博客，只需要三步如果你重装了系统或者更换了新电脑/新平台，怎么才能快速恢复原来的博客呢？如果你保留了原来博客文件夹下所有文件，那么恢复博客只需要三步： 安装必备组件包括：安装Git，安装Node.js Github配对打开git bash，在用户主目录下运行：1ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 把其中的邮件地址换成自己的邮件地址，然后一路回车,在用户主目录下生成.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH key密钥对，id_rsa是私钥登陆GitHub，打开「Settings」-&gt;「SSH and GPG keys」，然后点击「new SSH key」，填上任意Title，在Key文本框里粘贴公钥id_rsa.pub文件的内容），最后点击「Add SSH Key」测试是否配对成功：1ssh -T git@github.com 安装hexo打开git bash客户端，输入1npm install hexo-cli -g ，开始安装hexo安装成功后，进入你原来的博客目录，就可以用hexo命令进行博客生成和部署啦~ 给博客自定义域名开启HttpsHTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer 或 Hypertext Transfer Protocol Secure，超文本传输安全协议），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。GitHub官方在5月1号宣布，GitHub Pages的自定义域名获得对HTTPS的支持。但是因为自己的域名是自定义的，购于阿里云，因此不能直接在Setting中设置Enforce HTTPS:而Github pages不支持SSL证书上传，因此，开启HTTPS需要借助CloudFlare的CDN代理。即用户到CDN服务器的连接为https，而CDN服务器到GithubPage服务器的连接为http，就是在CDN服务器那里加上反向代理。步骤如下： 首先注册并登陆CloudFlare,在域名购买的地方修改name sever，修改DNS解析地址。（启用动态DNS加速） 与域名绑定并激活成功后，设置CloudFlare 的 DNS： 设置CloudFlare 的 Crypto： 设置路由规则Page Rules：至此，等待一段时间，就可以用https协议访问你的自定义域名为了让博客完全开启Https，还需要修改文章内容中用http协议的链接，比如图片，这样，就能看到浏览器域名旁边的小绿锁啦！同时，修改了DNS解析服务器后，网站响应速度也更快了！一举两得！]]></content>
      <categories>
        <category>Guidances</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CUDA安装问题解决]]></title>
    <url>%2F2018%2F07%2F29%2FCUDA%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[摘要：CUDA安装失败问题解决。 问题 CUDA安装失败都是由于其中Visual Studio(VS) Intergration无法安装导致： 解决办法 择自定义安装，并不要安装VS组件： 将“CUDAVisualStudioIntegration\extras\visual_studio_integration\MSBuildExtensions”下的文件直接拷贝到“C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\BuildCustomizations”文件夹中。 “CUDAVisualStudioIntegration”这个可以在默认文件：“C:\Users\用户名\AppData\Local\Temp\CUDA”下找到，但是如果你把NVIDIA安装程序关闭了，那么这个默认文件就会消失的，所以可以等NVIDIA安装程序将数据解压完毕后再去找，肯定能找到。 复制解压后的cudnn文件到cuda对应目录下即可。最后验证安装成功： 12345C:\Users\wufan&gt;nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2017 NVIDIA CorporationBuilt on Fri_Sep__1_21:08:32_Central_Daylight_Time_2017Cuda compilation tools, release 9.0, V9.0.176]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux之路]]></title>
    <url>%2F2018%2F07%2F22%2FLinux%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[摘要：记录使用Linux遇到的问题与解决办法。 无法解析或打开软件包的列表或是状态文件问题的解决方案在通过sudo apt-get install安装软件的时候，可能会出现:1234正在读取软件包列表... 有错误！E: Encountered a section with no Package: headerE: Problem with MergeList /var/lib/apt/lists/??E: 无法解析或打开软件包的列表或是状态文件。 解决方案执行下面两条语句：12sudo rm /var/lib/apt/lists/* -vf #删掉apt下的lists文件下的内容sudo apt-get update # 更新软件源]]></content>
      <categories>
        <category>Operating Systems</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JupyterNotebook教程]]></title>
    <url>%2F2018%2F07%2F15%2FJupyterNotebook%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[摘要：简单总结Jupyter Notebook的教程,方便以后使用。 notebook 界面组成 notebook 的名称 主工具栏，提供了保存、导出、重载 notebook，以及重启内核等选项 快捷键 notebook 主要区域，包含了 notebook 的内容编辑区 两种模式Command mode 和 Edit mode。 在一个cell中，按下Enter,进入Edit模式，按下Esc,进入Command 模式 运行当前cell，并移动到下一个Cell在一个cell中（在command模式下）, Shift + Enter 创建Cell在一个cell中（在command模式下） 按下 a ,即可在这个cell之前创建一个新的cell； 按下 b,即可在这个cell之后创建一个新的cell; Cell中 Code 和 Markdown的切换在一个cell中（在command模式下） 按下y, 进入Code; 按下m, 进入Markdown; 显示Cell中的行数在一个cell中（在command模式下），按下 l 删除Cell在一个cell中（在command模式下）, 按两次d 保存Notebook在一个cell中（在command模式下）, 按下s 启动命令面板在一个cell中（在command模式下）, 按下 Ctrl + Shift + P界面中的小键盘图标也可以启动。 可以通过这个命令面板快速的执行命令。比如我这里将一个cell移动到它下一个cell的下面：在一个cell中（在command模式下），然后按下 Ctrl + Shift + P ，输入 move ，键盘方向键选择要执行的命令即可，然后按下回车即可执行。 Matplotlib 集成如果你用 Python 绘制过图形，那你肯定知道 matplotlib。Matplotlib 是一个用于创建漂亮图形的 Python 库，结合 Jupyter notebook 使用时体验更佳。 要想在 Jupyter notebook 中使用 matplotlib，需要告诉 Jupyter 获取 matplotlib 生成的所有图形，并将其嵌入 notebook 中。为此，需要计算：1%matplotlib inline 译注：要想执行成功，需要先1pip install matplotlib。 运行这个指令可能要花个几秒钟，但是在 notebook 中需要执行一次即可。接下来，我们来绘制一个图形，看看具体的集成效果： 1234567import matplotlib.pyplot as pltimport numpy as npx = np.arange(20)y = x**2plt.plot(x, y) 上面的代码将绘制方程式 y=x^2 。计算单元格后，会得到如下图形： 终极奥义按下键盘的 h。查看所有快捷键~~]]></content>
      <categories>
        <category>Guidances</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>jupyter notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Donkeycar教程]]></title>
    <url>%2F2018%2F07%2F13%2FDonkeycar%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[摘要：本教程是基于Donkeycar的智能小车教程。DonkeyCar小车是基于树莓派和Python，利用Keras深度学习框架实现的自动驾驶小车。 简介本教程是基于Donkeycar的智能小车教程。DonkeyCar小车是基于树莓派和Python，利用Keras深度学习框架实现的自动驾驶小车。本文档参考和整合Donkeycar文档和创客智造的中英文教程，以及安装可能碰到的问题，以“HSP无限94186 ——1比16有刷无控车型”为模型作详细演示，从硬件，软件，系统整合，模型修改等方面介绍Donkeycar智能小车的实现。整体框架：1) Vehicle - a container class to hold and manage all aspects of the vehicle.2) Parts - modular components of the vehicle that read/write to the memory. This includes sensors, actuators, remote controlers and a datastore.3) Memory - holds the state of the vehicle and is used to pass variables between parts.4) Drive loop - a function of the vehicle that runs ensures each part interacts with the memory. 硬件硬件清单配件明细模型要求：我们需要选择：①独立ESC（电子调速器）和接收机的RC小车②选择三线连接器，三线舵机③选择速度更慢的有刷小车模型更容易实现。 推荐配置参考：1:16模型配置 1:10模型配置参数解释：motor是电机的参数，2040就是表示定子外径是20mm，定子高度是40mm，定子的外径和高度越多，定子的铁芯越大，线圈绕的匝数也越多，表现出来就是电机的功率越大。无刷电机KV值定义为转速/V，意思为输入电压增加1伏特(V)，无刷电机空转转速（转/分钟）增加的转速值。ESC的25A是指持续电流25A，这个峰值电流是85A，BEC输出5V，1A。Tcaction：四驱，双差速器。Groung Clearance：小车底部离地面的距离。 购买配置清单（价格仅供参考，更新于2018-7-3） 名称 淘宝地址 价格（税点费+邮费）/元 备注 小车主体 https://item.taobao.com/item.htm?spm=a1z10.1-c.w4004-10687857697.2.14566a1aBpsYGj&amp;id=524795742343 329.8(+20) 无限94182——1比16有刷无控车架（有刷不要遥控）电调（已包含）舵机（已包含） USB电池 https://detail.tmall.com/item.htm?spm=a230r.1.14.9.2c9e646ctC49zM&amp;id=564303977283&amp;cm_id=140105335569ed55e27b&amp;abbucket=13&amp;skuId=3563362700791 49(0.2) 2A 5V输出，小米充电宝 树莓派3B+ https://item.taobao.com/item.htm?spm=a1z10.5-c-s.w4002-14802299686.14.485c40da2EhCk5&amp;id=527630316715 354(21.64) 3B E14中国版 套餐16G，包括SD卡及配件 广角摄像头 https://item.taobao.com/item.htm?spm=a1z10.5-c-s.w4002-14802299686.26.54ba6ae1HJKd7d&amp;id=537191521576 100(6.72) 树莓派摄像头5MP 树莓派杜邦线 https://item.taobao.com/item.htm?spm=a1z10.5-c-s.w4002-14802299686.23.2fd00909E38MRt&amp;id=18189793269 2 树莓派连接线 电机驱动芯片 PCA 9685 https://detail.tmall.com/item.htm?spm=a230r.1.14.1.3bc5178b59bMmJ&amp;id=538283746663&amp;cm_id=140105335569ed55e27b&amp;abbucket=1 15(+5.4) 资料下载https://pan.baidu.com/s/1miRuKti 3D打印架 CAD Files: a360.co/2pf3Dam STL Files: thingiverse.com/thing:2260575 x 需要3D打印机 配件介绍HSP无限94182模型参数：模型结构： 电调（Electronic Speed Control，ESC）电子调速器，主要有两个作用，一是将电池降压，适合接收机和其他舵机的工作电压；二是从接收机获得油门信号，控制马达的转速，从而改变飞机的速度。❤连接方式为：1、电调的输入线与电池连接；2、电调的输出线（有刷两根、无刷三根）与电机连接；（在我们用到的有刷模型中，是红色和黑色的两根比较粗的线）3、电调的信号线（三根红色，白色和黑色的较细的线）与接收机（PCA驱动芯片）连接。 舵机舵机的工作原理：舵机常用的控制信号是一个周期为20毫秒左右，宽度为1毫秒到2毫秒的脉冲信号。当舵机收到该信号后，会马上激发出一个与之相同的，宽度为1.5毫秒的负向标准的中位脉冲。之后二个脉冲在一个加法器中进行相加得到了所谓的差值脉冲。输入信号脉冲如果宽于负向的标准脉冲，得到的就是正的差值脉冲。如果输入脉冲比标准脉冲窄，相加后得到的肯定是负的脉冲。此差值脉冲放大后就是驱动舵机正反转动的动力信号。舵机电机的转动，通过齿轮组减速后，同时驱动转盘和标准脉冲宽度调节电位器转动。直到标准脉冲与输入脉冲宽度完全相同时，差值脉冲消失时才会停止转动。❤连接方式：将输出的三线与对应的PCA驱动板引脚连接。电调和舵机都是标准3线母插头连接只要按照对应的引脚插入驱动板就可以了。(地线一般为黑色或棕色、信号线一般为黄色或白色)。 树莓派+miscro SD存储卡：Raspberry Pi(中文名为“树莓派”,简写为RPi，(或者RasPi / RPI) 1 是为学习计算机编程教育而设计，只有信用卡大小的微型电脑，其系统基于Linux。关于树莓派的详细教程参考7。Raspberry Pi 3B+主板图解：树莓派主板图解 树莓派引脚GPIO定义❤连接方式：1、USB电源接口接入充电宝电源2、摄像头接口连接摄像头3、树莓派和PCA9685连接：只连四根线，3.3v，两根 I2C 引脚 (SDA 和 SCL)，地线 ground。 PCA电机驱动芯片9685（舵机驱动板）资料下载：https://pan.baidu.com/s/1miRuKti详细教程参考9。 PCA9685是一款基于IIC总线通信的12位精度16通道PWM波输出的芯片, 可用于控制舵机、led、电机等设备，i2c通信，节省主机资源。❤连接和使用方式：1、 连接树莓派：GND -&gt; RPi GND（9脚）SCL -&gt; RPi SCL1（5脚）SDA -&gt; RPi SDA1（3脚）VCC -&gt; RPi 3.3V （1脚）V+ -&gt; RPi 5V（本实验中PCA上的V+接口不需要接入电源） 树莓派和PCA9685连接图2、 连接舵机和电调：电调和舵机都是标准3线母插头连接只要按照对应的引脚插入驱动板就可以了。(地线一般为黑色或棕色、信号线一般为黄色或白色，所以对应黑色的线要插在GND对应的针头)。 PCA9685连接图在上图中，两股标准3线母插头分别连接舵机与电调。 广角摄像头WARNING：不要在树莓派开机时插拔摄像头！摄像头需要满足的参数：购买的Camera 5MP广角摄像头参数： 充电宝提供5v2A的usb输出和12V输出，主要给树莓派供电❤连接方式：将充电宝的输出microusb输出连接到树莓派的电源输入端。 3D打印架❤用螺丝和销钉固定在小车车架上。 杜邦线杜邦线可用于实验板的引脚扩展，增加实验项目等。可以非常牢靠地和插针连接,无需焊接,可以快速进行电路试验。本实验中，用来连接树莓派与PCA驱动芯片的对应引脚。 硬件组装组装流程1)，2)两步为3D打印步骤，如果不适用3D打印，可以用纸板和小刀手工完成顶部结构。1) 打印部件（3D打印）用黑色PLA打印零件，层高2毫米，没有支撑。顶部翻转杆设计成倒置打印。用黑色PLA打印零件，0.3mm层高，一个0.5mm喷嘴，没有支撑。顶部翻转杆设计成倒置打印。打印的结构图：2) 清理零件（手工修正）几乎所有3D打印部件都需要清理。重新钻孔，并清理多余的塑料。 3) 组装顶板结构，树莓派电源充电宝顶部结构手工完成后的图片： 4) 将PCA驱动板连接到树莓派利用杜邦线连接，对应的针脚如下：GND -&gt; RPi GND（9脚）SCL -&gt; RPi SCL1（5脚）SDA -&gt; RPi SDA1（3脚）VCC -&gt; RPi 3.3V （1脚）V+ -&gt; RPi 5V（本实验中PCA上的V+接口不需要接入电源）本实验只需要连接四个针脚即可。 5) 将树莓派和PCA驱动板附加到3D打印的底板上。 6) 安装摄像头使用摄像头前，取下相机镜头上的塑料薄膜。安装方式：将树莓派上摄像头插销扒开，插入相机电缆，注意触点的位置，随后按入插销即可。 7) 硬件整合舵机与电调已经在小车上固定好，所以接下来只需用三线母插头把PCA驱动板连接舵机与电调。因为电调和舵机都是标准3线母插头连接只要按照对应的引脚插入驱动板就好。(地线一般为黑色或棕色、信号线一般为黄色或白色，所以对应黑色的线要插在GND对应的针头)。 组装完成几种不同形态智能小车的完成体： 软件软件清单❤系统：树莓派系统Ubuntu系统❤在linux下安装donkeycar安装依赖：virtualenv build-essential python3-dev gfortran libhdf5-devhttps://github.com/wroscoe/donkey❤在Windows下安装donkeycarhttps://conda.io/miniconda.htmlhttps://git-scm.com/download/wingit库https://github.com/wroscoe/donkey❤在MAC下安装donkeycarhttps://conda.io/miniconda.htmlhttps://www.atlassian.com/git/tutorials/install-gitxcode-select –installpip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py3-none-any.whl开源机器学习框架：❤pip install keras==2.0.6❤pip install tensorflow==1.3.0 软件安装安装树莓派系统将SD卡用读卡器连接到本地PC。首先为树莓派安装固件，下载地址：https://www.dropbox.com/s/wiudnm2dcsvoquu/donkey_v22.img.zip?dl=0安装步骤：方法1：使用6中的推荐步骤方法2：利用安装软件Etcher。 安装方法参考教程（For ubuntu）,（For windows）。 设置wifi连接我们需要让树莓派连接wifi热点，从而可以无线操控小车。方法有两种：方法1：SD卡插入树莓派，显示屏，键盘和鼠标连入树莓派，开机后通过界面链接wifi。方法2：（没有显示屏和键鼠条件下）首先，新建一个无线热点。可以使用本地PC新建wifi热点。记录ssid和password。接下来修改树莓派的系统文件：在boot部分的根目录下，新建文件名为wpa_supplicant.conf的文件，文件内容为1234567country=USctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdevupdate_config=1network=&#123; ssid=&quot;&lt;your network name&gt;&quot; psk=&quot;&lt;your password&gt;&quot;&#125; 分别在ssid和psk设置自己的WiFi用户名和密码，注意不能有&lt;&gt;， 设置主机名如果网络中有多个树莓派，还需要修改本树莓派的用户名,以下命令需要将sd卡挂载到Linux上运行，由于创建本文档时只有一个树莓派，所以并没有修改用户名，本文档的所有用户名均为pi，若读者对树莓派的用户名有修改，登录时需要改成自己的用户名和密码。12sudo vi /media/userID/UUID/etc/hostnamesudo vi /media/userID/UUID/etc/hosts 注意用户名只能是小写。然后把SD卡插进树莓派里，给树莓派上电。 设置SSH远程登录首先查看网络环境，树莓派连接的网络是本地连接13创建的共享热点：用抓包工具或者nmap扫描工具查找树莓派的ip地址：或者可以用cmd自带的ARP命令查看相应地址的ARP缓存也可以找到小车地址，arp -a从上图可以找到树莓派的ip地址是192.168.155.2，接着通过ssh登录树莓派，用户名pi,密码asdfasdf ，登录进去之后界面如图所示：另外，可以通过win10自带的移动热点看到连接设备的IP地址：推荐使用的ssh客户端登录软件比如Xshell。 在树莓派镜像安装，升级donkeycar存储卡图像上的donkeycar Python代码可能比Github repo上的要早，所以一旦你运行了Pi，需要更新，在ssh客户端连接树莓派后，键入命令如下：123cd ~/donkeycargit pullpip install -e . 在本地PC安装donkeycar并创建本地工作目录接下来是在本地笔记本电脑或服务器上设置相同的代码库，以便测试和训练智能小车。安装因平台而异。有如下三种方法，仅给出了windows上的安装结果。 Windows系统❤安装miniconda Python 3.6 64 bit. https://conda.io/miniconda.html❤确保选中该框以允许它修改您的系统路径变量以添加conda。❤安装git 64 bit，https://git-scm.com/download/win❤从开始菜单启动Anaconda❤更改为您希望用作项目主管的目录12mkdir projectscd projects ❤安装donkeycar12git clone https://github.com/wroscoe/donkeycd donkey ❤创建Python Anaconda环境12conda env create -f envs\windows.ymlactivate donkey ❤安装代码源并创建您的本地工作目录：12pip install -e .donkey createcar --path ~/d2 #本地工作目录名称设置为d2，可以自己定义 安装结果：注意：在关闭Anaconda提示符后，当再次打开它时，您需要键入activate donkey以重新启用映射到特定于donkey的Python库。（关于anaconda的使用，可以参考10）项目主管目录示例：创建的本地工作目录示例： Linux系统❤安装依赖和python环境12345sudo apt-get install virtualenv build-essential python3-dev gfortran libhdf5-devvirtualenv env -p python3source env/bin/activatepip install keras==2.0.6pip install tensorflow==1.3.0 ❤安装donkeycar12git clone https://github.com/wroscoe/donkey donkeycarpip install -e donkeycar Mac系统❤安装miniconda Python 3.6 64 bit. https://conda.io/miniconda.html❤安装git 64 bit，https://git-scm.com/download/win❤启动终端❤如果Xcode or gcc 没安装1xcode-select --install ❤创建项目根目录12mkdir projectscd projects ❤下载donkeycar12git clone https://github.com/wroscoe/donkeycd donkey ❤创建Python Anaconda环境12conda env create -f envs/mac.ymlsource activate donkey ❤安装Tensorflow1pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py3-none-any.whl ❤安装donkey12pip install -e .donkey createcar --path ~/d2 注意：关闭终端后，当您再次打开终端时，您需要键入1source activate donkey 来重新启用映射到特定于donkey的Python库。 运行智能小车WARNING：先放置到安全地方并让轮子离地！ Windows系统-打开Anaconda-激活映射到donkey的Python设置：donkey123```-进入管理donkey的本地目录：```cd ~/d2 远程登录树莓派-用Xshell登录，详细见3.2.4节。 启动和控制小车-在Xshell连接成功后，打开你小车目录，并开启小车12cd ~/d2python manage.py drive -这个脚本将启动你的小车，其中包括一个作为Web服务器的部件，以便控制你的小车。-现在可以通过以下网址从网络浏览器控制您的汽车：1&lt;your car&apos;s IP&apos;s address&gt;:8887 接下来在本地PC通过浏览器（推荐Chrome浏览器）登录上述网址，在web端控制智能小车： 校准小车小车的配置信息是存在config.py脚本中的，这个脚本会在运行1donkey createcar --path ~/d2 这个命令之后出现在”./d2”这个目录下，如下所示：其内容是各个部件的参数配置：校准小车的目的就是将上述参数调整到合适的值，这样才能顺利的驾驶小车，以及共享同款小车的校准数据。 舵机校准（转向校准）要填的数据有：注意，此时应让小车离开地面，避免乱跑1、 打开小车，找到舵机伺服电缆插到了PCA的那个通道上了，应该是1或者0.2、 运行命令1donkey calibrate --channel &lt;your_steering_channel&gt; 3、 输入 360’会看到小车的轮子轻微转动，如果没有的话就输入400或者3004、 左右调整 +/- 10，一直到轮子完全转向左边或者右边，记录此时的值，并填入config.py 马力校准（电机控制）需要校准的参数：1、 找到ESC的电缆，看看它插到PCA的哪个位置，这就是马力通道。2、 运行命令1donkey calibrate --channel &lt;your_throttle_channel&gt; 当提示输入PWM值的时候输入370，此时应该能听到ESC发出哔哔声，表示已经经过校准。3、 输入400，这时小车应该就能往前走了，如果不能往前，则有可能是反向的，此时应该输入3304、 多尝试几次，直到找到你认为比较合适的最大速度，记下此时的PWM值。 校准微调现在小车已经校准过了，可以开动小车查看是否按照预期运行：1、 运行1python manage.py drive 命令启动小车2、 在浏览器中访问1&lt;your_cars_ip_address&gt;:8887 3、 按j，一直到小车的方向完全转向右边4、 按i，一直到小车的方向完全朝向前方5、 测量转弯直径，并将它记录在表格中6、 在不同的转向值下重复同样的测量7、 绘制表格看看小车在各个方向的转向是否相同（角度相同时）如果你的转向在80%PWM和100%PWM相同时，将PWM值变为80%PWM,如果你的车往一边偏，改变另一边的PWM值经过微调之后你的表格大概会是这个样子 训练智能小车赛道设置可以用带颜色的胶带、丝带或者绳子，赛道最好宽4英尺，并且有2英寸的白色边框和黄色虚线中线。 数据收集① 先不记录数据，在跑道上跑几圈，当熟练跑道之后（10圈以上不出错）点击按钮Start Recording② 如果出错或者有意外发生时马上点击Stop Car停止记录③ 至少收集10-20圈好的数据之后即可以停止收集，Ctrl-c即可，收集的数据在data文件夹里 需要注意的细节：1， 清除d2/data目录下的之前的数据2， 回到d2目录下 python namage.py drive启动小车3， 到浏览器中model选择user，然后用电脑控制小车在场景下跑几圈4， 等到操作小车在场景下基本不出错之后点击start recording开始记录数据5， 记录大约半个小时的数据就可以了注意在记录数据的过程中，可能会出现小车没电的情况，解决的办法就是，刚开始在config.py文件中把THROTTLE_FORWARD_PWM设置的小一点，本车是335或者330，过一会感觉小车跑的变慢了，停止记录，停下小车，关闭程序。调整THROTTLE_FORWARD_PWM变大一点到440，重启程序，记得保持小车的运行速度以及Throttle差不多一致。同理慢慢可以变为445和4506， 记录完数据，筛选数据。手动删除数据中撞墙等不好的数据7， 将数据考到电脑上装的donkey的d2/data目录下（小文件太多，速度会特别慢）8， 进入d2目录，运行命令 python manage.py train –model ~/d2/models/mypilot9， 等待训练结束，到到d2/models下将mypilot文件发送到小车的对应目录下10， 用命令python manage.py drive –model ~/d2/models/mypilot启动小车，然后到浏览器中选择local pilot模式启动自动驾驶 拷贝数据至本地PC由于树莓派计算能力有限，需要将数据迁移到电脑上进行模型的训练，有两种方法：方法1：新开一个SSH窗口用rsync命令从树莓派复制数据。命令如下：rsync -r pi@&lt;your_pi_ip_address&gt;:~/d2/data/ ~/d2/data/方法2：利用Xshell里面的新建文件传输直接复制粘贴。 利用keras训练模型复制好数据之后就可以运行训练脚本：1python ~/d2/manage.py train --tub &lt;tub folder names comma separated&gt; --model ./models/mypilot 或者：1python ~/d2/manage.py train --model ~/d2/models/mypilot 拷贝模型至树莓派训练好之后再讲pilot迁移回树莓派：1rsync -r ~/d2/models/ pi@&lt;your_ip_address&gt;:~/d2/models/ 用自动驾驶模型启动小车重新启动小车，将训练好的模型穿进去：1python manage.py drive --model ~/d2/models/mypilot 用模拟器训练小车*用于生成训练用的图片，测试自动驾驶仪等。当然你也可以不用这种方法，根据网页【http://docs.donkeycar.com/guide/build_hardware/】的描述，你也可以先用手机控制小车在赛道上开10-20次来收集训练数据。下载之后直接双击EXE文件运行，你可以在input里面看到控制按钮信息。模拟器中共有三个场景，但是网站【http://docs.donkeycar.com/guide/simulator/】中只给了前两种的描述，第三种是sparkfun AVC机器人大赛的场景：Generated Road Scene：通用场景The purpose of this is to create a randomly generated road so that you can have miles of curves on different road surfaces. You can train on one road and test on something similar, or a totally different surface.Warehouse Scene：专用场景The purpose of this is to create a specific track that is somewhat similar to an actual course in use as the primary track for the Oakland DIYRobocars Meetup. 进入模拟器，右上角可以选择操作选项，根据网站【http://docs.donkeycar.com/guide/simulator/】的介绍，Joystick/Keyboard No Rec的意思就是摇杆或者键盘控制，但是数据不记录，其他选项意思类推。Next Track：在生成的道路场景中，这将改变路面和轨道宽度。Regen Track：使用当前的表面类型，但生成一个新的随机路径和路径。下图为我用键盘控制时的截图，在网站【http://docs.donkeycar.com/guide/simulator/】的介绍中，有一个注意事项是这样描述的：Note: Keyboard data produces steering information that is stepped (ie. -1, 0, +1) and may be difficult to train with. See below for joystick setup.大意是说由于键盘控制并不像摇杆可以产生连续的转向信息，而只能是间断的，所以并不适合用来训练。键盘控制页面下图为自动驾驶页面，可以看到左下角一共有四个参数，目前并没有搞得很清楚这四个参数的具体含义，暂且先贴出网页【http://docs.donkeycar.com/guide/simulator/】上的解释：Max Speed：这个应该就是决定了自动驾驶的最大速度This setting determines the target speed during the PID auto drive. It will also affect the speed when driving by keyboard controls (not recommended).Prop：转向角度This is short for proportional. This is the P part of PID that attempts to adjust steering back to the path in proportion to the deviation.Diff：为了防止角度调整过大This is the D part of PID that attempts to limit steering back to the path as derivative to the trend of deviation, designed to limit overshoot.Max SteeringMax steering can only be adjusted when using Auto Drive No Rec. It will also affect joystick and keyboard steering range, and should be saved and reloaded for you.另外关于这个参数，原文中有一个注意事项： Max Steering is an important adjustment. This affects categorical training quite strongly. As the steering data is normalized when written, and multiplies after coming from Python, this angle should remain constant over training and simulation. Take care when changing this value. And separate data and models by max steering setting.自动驾驶时的截图训练结束后，在log目录中会有训练的图片，图片大小为160*120像素贴一个网页【http://docs.donkeycar.com/guide/simulator/】上给出的典型用法，方便以后使用。 更新DonkeycarV2.5教程 用Etcher给SD卡写入树莓派系统镜像文件名为：donkey_2.5.0_pi3.img，新建并编辑boot目录下的wpa_supplicant.conf文件。 SSH连接树莓派并登陆。 12用户名：pi密码：raspberry 在树莓派上安装Donkeycar V2.5.1环境 12a) pip install donkeycar[pi]b) donkey createcar ~/ 在windows上安装DonkeycarV2.5.1（注意区分本地工作目录与本地代码目录）a) 新建一个本地代码目录，存放代码库： 12mkdir projectscd projects b) 从github上clone最新的donkeycar代码库12git clone https://github.com/wroscoe/donkeycd donkey c) 安装donkeycar资源环境，新建本地工作目录（mycar）12pip install -e .donkey createcar C:\Users\WuFan\new_mycar(自己修改) 会遇到的问题：a) ModuleNotFoundError: No module named ‘controller’：解决办法：将文件（可直接复制粘贴word中的这个文件）拷贝至\donkey\donkeycar\parts对应的本地代码目录下。修改本地工作目录中文件“manage.py”中第24行，修改为：1from donkeycar.parts.controller import LocalWebController, JoystickController b) 训练后的数据存放在树莓派tub文件夹下，而不是data 训练的时候，把tub文件夹下所有数据复制到本地工作目录下的data文件夹下。再开始训练。 c) 大家在用训练的模型驾驶的时候，切换到local pilot时，可能会遇到类似摄像头框消失，树莓派报错的情况。 这是因为树莓派上有的python文件版本和本地电脑从github上面clone的文件不一致。如果有报这种错误，可以把本地代码库上面的对应文件覆盖到树莓派上解决。 参考创新方向无人驾驶车障碍竞速无人取件车/送餐车/领路车无人捡球车参考文献 https://docs.donkeycar.com/ https://www.ncnynl.com/archives/201804/2398.html https://github.com/OSSDC/donkey https://github.com/wroscoe/donkey\ https://docs.donkeycar.com/guide/build_hardware/ https://www.donkeycar.com/ http://www.makerspace.cn/thread-5681-1-1.html https://www.raspberrypi.org/blog/self-driving-car/ https://blog.csdn.net/nicekwell/article/details/53616277 https://python.jobbole.com/87522/ https://bbs.pediy.com/thread-221193.htm https://www.xue51.com/soft/2044.html]]></content>
      <categories>
        <category>Guidances</category>
      </categories>
      <tags>
        <tag>donkeycar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Conda常用命令]]></title>
    <url>%2F2018%2F05%2F02%2FConda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要：使用Anaconda管理python各种python环境和库，可以极大提高在不同项目切换的效率。 帮助与版本 查看当前conda版本 12conda -Vconda -version 更新conda 12conda update condaconda update anaconda #更新anaconda 某个命令的帮助信息 1conda install --help 环境管理 查看当前环境 1conda info -e 查看所有环境 12conda info --envsconda env list 创建新的环境 123456conda create --name environment_name#创建不同python版本的环境conda create --name environment_name python=3.6conda create --name environment_name python=2.7#创建时添加库的环境conda create --name environment_name numpy scipy 切换环境 123456#切换到新环境activate environment_name#在linux于macos系统中，激活环境的命令为：source active environment_name#退出环境deactivate environment_name 移除环境 12#conda remove --name environment_name --allconda remove -n py36 --all 复制某个环境 1conda create --name new_name --clone old_name 保存环境配置信息 1conda env export &gt; environment.yml 读取环境配置信息 1conda env create -f environment.yml Note: 当遇到错误”SpecNotFound: Can’t process without a name”时，因为导入环境时目录有问题，所以需要检查.yml文件的path是否有误。 包管理 列举当前环境下所有包 1conda list 列举某个环境下所有包 1conda list -n environment_name 查找某个包 1conda search package_name 为指定环境安装某个包 1conda install -n environment_name package_name 更新包 1conda update package_name 卸载包 1conda remove package_name 设置镜像访问国外资源网速较低时，可以考虑改变源，使用国内镜像1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --set show_channel_urls yes]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>conda</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对抗攻击防御策略一览]]></title>
    <url>%2F2018%2F04%2F17%2F%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E9%98%B2%E5%BE%A1%E7%AD%96%E7%95%A5%E4%B8%80%E8%A7%88%2F</url>
    <content type="text"><![CDATA[摘要：根据最近的学习，按照自己的理解给不同对抗攻击的防御方法作简单总结。对抗防御从形式上看可以被分为三类：①对抗样本检测；②改变对抗样本；③增强模型。 ①对抗样本检测：指根据对抗样本与原始样本的分布差异，在模型Inference阶段将对抗样本区分出来。 检测对抗样本的方法有： 1） 基于统计检验的检测（Sample statistic）：这种方法比较直接，效果也比较差，并且因为是基于大量对抗样本的统计结论，因此需要大量对抗样本挖掘其统计规律，在检测的时候也不适于检测单个对抗样本。常见的统计检验方法如下：A． Maximum mean discrepancy and energy distance.【Kathrin Grosse, Praveen Manoharan, Nicolas Papernot, Michael Backes, and Patrick McDaniel. On the (Statistical) Detection of Adversarial Examples. arXiv preprint arXiv:1702.06280, 2017.】 但是这种方法不能对单个样本作出预测，只能揭示对抗样本与原始样本在平均偏差和距离的差异，不具有检测对抗样本的可行性。B． Kernel density estimation【Reuben Feinman, Ryan R Curtin, Saurabh Shintre, and Andrew B Gardner. Detecting Adversarial Samples from Artifacts. arXiv preprint arXiv:1703.00410, 2017.】这种方法即是在折叠的空间中计算一个测试样本和所有初始样本的距离，根据数据特征降维之后的差异区分对抗样本和真实样本。这种方法的缺陷是需要很大的计算资源，并且只能检测出对抗攻击时添加的对抗扰动比较大，让对抗样本和原始样本差异比较大的情况。C. 输入特征差异：包括JSMA攻击的论文中提到的，利用相邻像素间的平方差检测对抗样本。（这个方法前面的讨论中提到过，缺乏直观的合理性，所以也没什么价值） 2） 训练检测器（Detector）：将对抗样本和原始样本作为训练集进行监督训练。而检测器的训练包括两种：一种是直接将对抗样本和原始样本，打上label作为训练集训练一个分类器；另一种是将原始数据和对抗样本数据通过原始分类模型后，在输出层的值（或某一层神经网络层的输出值）打上label作为训练集训练一个分类器。 3） 预测结果差异（Prediction Inconsistency）根据预测结果差异来检测对抗样本主要有三种：(1)对抗样本和正常样本在原始模型的输出层差异。利用这种差异来检测对抗样本和原始样本，需要利用第2）点中构建一个检测器来实现；或者像我们前面的工作——根据模型输出层的统计差异来区分，但是这种方法不能对单个对抗样本做出判断。(2)对抗样本和原始样本经过特征处理之后，他们在输出层的变化不同。这种方法在前面的报告中提到了，这部分内容在后面的部分详细给出。(3)对抗样本在不同的模型下输出差异。这部分内容和前面和老师讨论的依据Byzantine Generals problem来设计系统相关联，让对抗样本经过多个分类模型，按照3t+1的原则，保证分类输出的正常。其中，不同的模型获得方式有很多，一种是其他能应用于同一个任务的分类模型，比如在用VGG16分类时，用ResNet，WRN，DenseNet等同样能用作分类的网络模型作为参照，检测出对抗样本。另外一种就是基于原始模型的修改，包括结构的修改和训练过程的修改，不同的修改过程可以得到不同的子模型。比如在训练过程中，每次训练采用不同的dropout策略，可以得到几个类似功能的分类模型，只要测试样本在这几个分类模型上满足拜占庭问题的解，就可以判断为是原始样本。 ②改变对抗样本：1）用对抗攻击的方法处理对抗样本，让对抗样本重新被分类准确。2）用特征处理的方法处理对抗样本，让对抗样本重新被分类准确。3) Denoise the adversarial perturbation4）添加去噪器，构建生成式模型，例如APE-GAN ③增强模型：1） 用更多数据训练，增强模型的泛化能力。包括对抗训练。2） 修改模型的激活函数或者损失函数。3） 使用network add-on，包括利用GAN，Defensive distillation。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
        <tag>papernotes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Academic Writing Lessons]]></title>
    <url>%2F2018%2F03%2F30%2FAcademic%20Writing%20Lessons%2F</url>
    <content type="text"><![CDATA[Academic Writing Lessons Use Better alternative words Original Better alternative consider evaluate,assess check verify,confirm different distinct,diverse,various,varied little/few seldom,slightly problem limitaion,restriction,obstacle,hindrance need require,stipulate affect influence,shape carry out implement,execute,primulgate,conduct change modify,adjust,alter,vary complicated complex,cumbersome,intricate correct/incorrect precise/imprecise,accurate/inaccurate find determine,derive,attain,locate,identify help assist,facilitate,guide,direct important critical,crucial,essential,pertinent,relevant,significant,vital improve enhance,upgrade,elevate is made of consists of,comprises,is composed of make clear elucidate,clarify makesure ensure,assure meet satisfy,fulfill,adhere to much/strongly markedly,considerably,substantially realize comprehend,preceive,understand solve alleviate,modify,resolve,eliminate,eradicate suitable appropriate,adequate tries attempts,aims,aspires usually normally,typically,generally very highly,rather,quite,extremely way method,means,approach,strategy whole complete,entire,comprehensive is found to be is is capable of can is view of the fact that because in this case here in some cases occasionally in no case never the question as to whether subsequent to after,following serves the function of is reach a conclusion is put an end to end provided that if come to a conclusion conclude by means of by in a position to can be deficient in lack at this point in time now at the present time now notwithstanding the fact that although manner in which how make inquiry regrading ask about,inquire about it is possible that may,might,could,can in most cases uaually in many cases often in large measure largely is in excess of exceeds,surpasses in proximity to near in case if in all cases always a number of several,many,numerous if conditions are such that if happens to be am,is,are give indication of indicate,suggest give consideration to consider for this reason because for the reason that so for the purpose of for/to during the time that while due to the fact that because despite the fact that althought at such time as when ascertain the location of find along the lines of such as a majority of most Formal Grammer and Style Avoid contracion Export figures will not improve until the economy is stronger. Export figures won&apos;t improve until the economy is stronger. Use the more appropriate formal negative forms. not...much -&gt; little not...any -&gt; no not...many -&gt; few Limit the use of “run on” expressions, such as “and so forth” and “etc.” These semiconductors can be used in robots, CD players, etc. —&gt; These semiconductors can be used in robots, CD players, and other electronic devices. Avoid addressing the reader as “you” You can see the results in Table 1. The results can be seen in Table 1. Limit the use of direct questions. Instead, use &quot;we now need to consider...&quot; Place adverbs within the verb. Then the solution can be discarded. The solution can then be discarded. The blood is withdraw slowly. The blood is slowly withdraw. Do not be wordy. (To be continued…)]]></content>
      <categories>
        <category>Guidances</category>
      </categories>
      <tags>
        <tag>lessons</tag>
        <tag>english</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python函数式编程]]></title>
    <url>%2F2018%2F03%2F29%2Fpython%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[python函数式编程 高阶函数map()和reduce()参考论文map(): 这个函数接收两个参数，一个是函数，一个是Iterable（可迭代对象），map将传入的函数$f(x)$依次作用到序列的每个元素上，并把结果作为新的Iterator（迭代器）返回。12#实现将一个数字序列转化成字符序列list(map(str,[1,2,3,4,5])) reduce(): 把一个函数作用在一个序列[x1, x2, x3, …]上，这个函数必须接收两个参数$f(x,y)$，reduce把结果继续和序列的下一个元素做累积计算。1234567#对一个序列求和&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; def add(x, y):... return x + y...&gt;&gt;&gt; reduce(add, [1, 3, 5, 7, 9])25 filter()用于过滤序列，和map()类似，filter()也接收一个函数和一个序列。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。返回一个Iterator（这说明返回的依旧是一个惰性序列）。 12345678910111213#删掉一个序列中的空字符串"""注意filter()给函数默认加bool()修正比如：bool(" a")=Truebool(" ")=Truebool(" ".Strip())=Falsebool(None)=False"""def not_empty(s): return s and s.strip()list(filter(not_empty, ['A', '', 'B', None, 'C', ' ']))# 结果: ['A', 'B', 'C'] 1234567891011121314151617#用filter()求素数的方法——埃氏筛法#定义一个筛选函数def _not_divisible(n): return lambda x: x % n &gt; 0#初始化自然数序列def _iter(): n = 1 while True: n = n + 2 yield ndef primes(): yield 2 it = _iter() while True: n = next(it) yield n it = filter(_not_divisible(n), it) 12345678910"""def _iter(): n = 1 while True: yield n n = n + 1"""def is_palindrome(n): return str(n) == str(n)[::-1]list(filter(is_palindrome),range(1000)) sorted()可以实现对list进行排序。同时，可以接受一个key 函数来实现自定义排序。12&gt;&gt;&gt; sorted([36, 5, -12, 9, -21], key=abs)[5, 9, -12, -21, 36] key指定的函数将作用于list的每一个元素上，并根据key函数返回的结果进行排序。1234&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'])['Credit', 'Zoo', 'about', 'bob']&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)['about', 'bob', 'Credit', 'Zoo'] 返回函数高阶函数除了可以接受函数作为参数外，还可以把函数作为结果值返回。1234567def lazy_sum(*args): def sum(): ax = 0 for n in args: ax = ax + n return ax return sum &hearts;&hearts;&hearts;&hearts; 闭包&hearts;&hearts;&hearts;&hearts;建议参考教程——知乎专栏闭包概念：在一个内部函数中，对外部作用域的变量进行引用，(并且一般外部函数的返回值为内部函数)，那么内部函数就被认为是闭包。&emsp;在函数lazy_sum中又定义了函数sum，并且，内部函数sum可以引用外部函数lazy_sum的参数和局部变量，当lazy_sum返回函数sum时，相关参数和变量都保存在返回的函数中，这称为“闭包（Closure）”的程序结构。&emsp;需要注意的问题是，循环在python中没有域的概念，向列表中添加函数的时候并不会保存循环中变量的值。返回的函数并没有立刻执行，而是直到调用了f()才执行。123456789def count(): fs = [] for i in range(1, 4): def f(): return i*i fs.append(f) return fsf1, f2, f3 = count() 你可能认为调用f1()，f2()和f3()结果应该是1，4，9，但实际结果是：123456&gt;&gt;&gt; f1()9&gt;&gt;&gt; f2()9&gt;&gt;&gt; f3()9 返回闭包时牢记一点：返回函数不要引用任何循环变量，或者后续会发生变化的变量。原因：闭包函数调用外部循环变量时，并没有保存这个值，只保存了变量的地址，要等到调用闭包函数时才会取具体的值，然而此时函数值可能已经发生了变化。解决办法：再定义一个函数，将g()形成闭包。主要是要在函数内部，把可变的循环值i作为函数参数调用。简单来说，一定要有f(i),在调用过程中，i就会被传入。123456789def count(): def f(j): def g(): return j*j return g fs = [] for i in range(1, 4): fs.append(f(i)) # f(i)立刻被执行，因此i的当前值被传入f() return fs 利用闭包返回一个计数器函数，每次调用它返回递增整数：1234567def createCounter() s=[0] def conter(): s[0] += 1 return s[0] return counter 外函数返回了内函数的引用：当我们在python中定义一个函数def demo(): 的时候，内存当中会开辟一些空间，存下这个函数的代码、内部的局部变量等等。这个demo只不过是一个变量名字，它里面存了这个函数所在位置的引用而已。我们还可以进行x = demo， y = demo， 这样的操作就相当于，把demo里存的东西赋值给x和y，这样x 和y 都指向了demo函数所在的引用，在这之后我们可以用x() 或者 y() 来调用我们自己创建的demo() ，调用的实际上根本就是一个函数，x、y和demo三个变量名存了同一个函数的引用。 闭包中内函数修改外函数局部变量： 在闭包内函数中，我们可以随意使用外函数绑定来的临时变量，但是如果我们想修改外函数临时变量数值的时候发现出问题了！ 在基本的python语法当中，一个函数可以随意读取全局数据，但是要修改全局数据的时候有两种方法:1 global 声明全局变量 2 全局变量是可变类型数据的时候可以修改 在闭包内函数也是类似的情况。在内函数中想修改闭包变量（外函数绑定给内函数的局部变量）的时候： 在python3中，可以用nonlocal 关键字声明 一个变量， 表示这个变量不是局部变量空间的变量，需要向上一层变量空间找这个变量。 在python2中，没有nonlocal这个关键字，我们可以把闭包变量改成可变类型数据进行修改，比如列表。 闭包的作用： 装饰器！！！装饰器是做什么的？？其中一个应用就是，我们工作中写了一个登录功能，我们想统计这个功能执行花了多长时间，我们可以用装饰器装饰这个登录模块，装饰器帮我们完成登录函数执行之前和之后取时间。 面向对象！！！经历了上面的分析，我们发现外函数的临时变量送给了内函数。大家回想一下类对象的情况，对象有好多类似的属性和方法，所以我们创建类，用类创建出来的对象都具有相同的属性方法。闭包也是实现面向对象的方法之一。在python当中虽然我们不这样用，在其他编程语言入比如avaScript中，经常用闭包来实现面向对象编程 实现单利模式！！ 闭包可以保存当前的运行环境，以一个类似棋盘游戏的例子来说明。假设棋盘大小为50*50，左上角为坐标系原点(0,0)，我需要一个函数，接收2个参数，分别为方向(direction)，步长(step)，该函数控制棋子的运动。 这里需要说明的是，每次运动的起点都是上次运动结束的终点。 匿名函数在传入函数时，有些时候，不需要显式地定义函数，直接传入匿名函数更方便。 1234567&gt;&gt;&gt; list(map(lambda x: x * x, [1, 2, 3, 4, 5, 6, 7, 8, 9]))[1, 4, 9, 16, 25, 36, 49, 64, 81]"""其中，lambda x: x * x相当于：def f(x): return x * x""" 同时，匿名函数可以作为返回函数。 装饰器（decorator）装饰器就是一个返回函数的高阶函数，基于闭包原理。定义一个打印日志的decorator:12345def log(func): def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper 定义一个带参数的decorator:1234567def log(text): def decorator(func): def wrapper(*args, **kw): print('%s %s():' % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator 函数也是对象，它有name等属性，但你去看经过decorator装饰之后的函数，123@logdef now(): print('2015-3-25') 它们的name已经从原来的’now’变成了’wrapper’：12&gt;&gt;&gt; now.__name__'wrapper' 因为返回的那个wrapper()函数名字就是’wrapper’，所以，需要把原始函数的__name__等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错。 不需要编写wrapper.__name__ = func.__name__这样的代码，Python内置的functools.wraps就是干这个事的，所以，一个完整的decorator的写法如下：12345678import functoolsdef log(func): @functools.wraps(func)#复制依赖函数 def wrapper(*args, **kw): print(&apos;call %s():&apos; % func.__name__) return func(*args, **kw) return wrapper 偏函数（Partial function）偏函数可以通过设定参数的默认值，降低函数调用的难度。由Python的functools模块提供。举例说明：123456&gt;&gt;&gt; import functools&gt;&gt;&gt; int2 = functools.partial(int, base=2)&gt;&gt;&gt; int2('1000000')64&gt;&gt;&gt; int2('1010101')85 上面的新的int2函数，仅仅是把base参数重新设定默认值为2，但也可以在函数调用时传入其他值：12&gt;&gt;&gt; int2(&apos;1000000&apos;, base=10)1000000 创建偏函数时，实际上可以接收函数对象、*args和**kw这3个参数，当传入：1234int2 = functools.partial(int, base=2)#相当于kw = &#123; &apos;base&apos;: 2 &#125;int(&apos;10010&apos;, **kw) Reference教程]]></content>
      <categories>
        <category>Languages</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python可变与不可变对象]]></title>
    <url>%2F2018%2F03%2F19%2Fpython%E5%8F%AF%E5%8F%98%E4%B8%8E%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[Abstract：介绍python中的可变对象与不可变对象的概念。 定义 不可变对象，该对象所指向的内存中的值不能被改变。当改变某个变量时候，由于其所指的值不能被改变，相当于把原来的值复制一份后再改变，这会开辟一个新的地址，变量再指向这个新的地址。 可变对象，该对象所指向的内存中的值可以被改变。变量（准确的说是引用）改变后，实际上是其所指的值直接发生改变，并没有发生复制行为，也没有开辟新的出地址，通俗点说就是原地改变。 例子 不可变（immutable）：int、字符串(string)、float、（数值型number）、元组（tuple) 可变（mutable）：字典型(dictionary)、列表型(list)、集合（set） 定义默认参数要牢记默认参数必须指向不变对象！1234567def add_end(L=[]): L.append('END') return L&gt;&gt;&gt; add_end()['END', 'END']&gt;&gt;&gt; add_end()['END', 'END', 'END'] Python函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。123456789def add_end(L=None): if L is None: L = [] L.append('END') return L&gt;&gt;&gt; add_end()['END']&gt;&gt;&gt; add_end()['END'] 代码示例123456789101112&gt;&gt;&gt; a = [1]&gt;&gt;&gt; id(a)2278158310408&gt;&gt;&gt; a += [2]&gt;&gt;&gt; id(a)2278158310408&gt;&gt;&gt; a = 4 #不可变&gt;&gt;&gt; id(a)1944540032&gt;&gt;&gt; a += 3&gt;&gt;&gt; id(a)1944540128 但是当不可变对象比较大时，这个规律不符合，并不会创建新的对象。常量池 python中的复制，浅拷贝和深拷贝复制只传递对象的引用，也就是对象的地址123456789101112131415&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = a&gt;&gt;&gt; a[1, 2, 3]&gt;&gt;&gt; b[1, 2, 3]&gt;&gt;&gt; id(a)1264995283336&gt;&gt;&gt; id(b)1264995283336&gt;&gt;&gt; a.append(2)&gt;&gt;&gt; a[1, 2, 3, 2]&gt;&gt;&gt; b[1, 2, 3, 2] 浅拷贝指把存放变量的地址值传给被赋值，最后两个变量引用了同一份地址。copy会根据数据类型为可变还是不可变进行判断：如果是不可变类型，和复制相同；如果是可变类型，只是拷贝第一层（也就是对于list类型中，其中的元素中指向的其他地址不变化）。用到的方法是 copy.copy()1234567891011121314151617181920212223&gt;&gt;&gt;import copy&gt;&gt;&gt; c=copy.copy(a)&gt;&gt;&gt; c[1, 2, 3, 2]&gt;&gt;&gt; id(c)1264997856200&gt;&gt;&gt; id(a)1264995283336&gt;&gt;&gt; a[1, 2, 3, 2]&gt;&gt;&gt; b=2&gt;&gt;&gt; c=copy.copy(a)&gt;&gt;&gt; id(a)1264995283336&gt;&gt;&gt; id(c)1264997856264&gt;&gt;&gt; d=copy.copy(b)&gt;&gt;&gt; id(b)1354853888&gt;&gt;&gt; id(d)1354853888 发现，同样是浅拷贝，拷贝后的a和b却给了不同的处理。因为a是list，是可变对象，而b是int数据类型，属于不可变对象。换言之，对于可变对象，浅拷贝与复制不同，拷贝的结果存放在一个新的空间。而对于不可变对象，拷贝和复制的意义相同，都指向同一个地址空间。12345678&gt;&gt;&gt; id(c)1264997856200&gt;&gt;&gt; id(a)1264995283336&gt;&gt;&gt; id(b)1354853888&gt;&gt;&gt; id(d)1354853888 但是，对于不可变对象，当改变某个变量时候，由于其所指的值不能被改变，相当于把原来的值复制一份后再改变，这会开辟一个新的地址，变量再指向这个新的地址。因此，改变一个变量，其地址会发生改变，而原来复制出的变量则指向原来的值。1234567891011121314151617181920212223242526272829&gt;&gt;&gt; a = 2&gt;&gt;&gt; b = a&gt;&gt;&gt; c = copy.copy(a)&gt;&gt;&gt; d = copy.deepcopy(a)&gt;&gt;&gt; id(a)1354853888&gt;&gt;&gt; id(b)1354853888&gt;&gt;&gt; id(c)1354853888&gt;&gt;&gt; id(d)1354853888&gt;&gt;&gt; a = a + 3&gt;&gt;&gt; a5&gt;&gt;&gt; b2&gt;&gt;&gt; c2&gt;&gt;&gt; d2&gt;&gt;&gt; id(a)1354853984&gt;&gt;&gt; id(b)1354853888&gt;&gt;&gt; id(c)1354853888&gt;&gt;&gt; id(d)1354853888 可见，对于不可变对象，深拷贝，浅拷贝，复制 效果一样。 深拷贝包含对象里面的内容的拷贝，重新开辟一个新的空间，所以原始对象的改变不会造成深拷贝里任何子元素的改变。（实际上，一般所谓的拷贝操作，都是在list上进行的，所以只需要知道在lists上着三种拷贝操作的意义和结论即可）深拷贝和浅拷贝的区别直接看代码：123456789101112131415161718192021222324252627282930313233&gt;&gt;&gt; a = [[1,1,1],[2,2,2]]&gt;&gt;&gt; b = copy.copy(a)&gt;&gt;&gt; c = copy.deepcopy(a)&gt;&gt;&gt; id(a)1264997889288&gt;&gt;&gt; id(b)1264997862472&gt;&gt;&gt; id(c)1264997889736#深拷贝和浅拷贝的区别在，深拷贝复制了整个对象，而浅拷贝只是复制了第一层的元素&gt;&gt;&gt; id(a[0])1264997875208&gt;&gt;&gt; id(b[0])1264997875208&gt;&gt;&gt; id(c[0])1264997861640&gt;&gt;&gt; a.append(2)&gt;&gt;&gt; b[[1, 1, 1], [2, 2, 2]]&gt;&gt;&gt; c[[1, 1, 1], [2, 2, 2]]&gt;&gt;&gt; a[[1, 1, 1], [2, 2, 2], 2]&gt;&gt;&gt; a[0].append(2)&gt;&gt;&gt; a[[1, 1, 1, 2], [2, 2, 2], 2]&gt;&gt;&gt; b[[1, 1, 1, 2], [2, 2, 2]]&gt;&gt;&gt; c[[1, 1, 1], [2, 2, 2]]]]></content>
      <categories>
        <category>Languages</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python惰性序列]]></title>
    <url>%2F2018%2F03%2F17%2Fpython%E6%83%B0%E6%80%A7%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[python中的高级特性——惰性序列 生成器generator一边计算一边循环的机制，称为生成器。generator非常强大。相比于传统的for循环直接生成一个list，generator可以节省大量的空间。1234567891011121314&gt;&gt;&gt; g = (x * x for x in range(10))&gt;&gt;&gt; for n in g:... print(n)...0149162536496481 如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。著名的斐波拉契数列（Fibonacci）1234567def fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1 return &apos;done&apos; 杨辉三角：12345678910def yanghui(max): line=[1] while True: yield line nextline = line+[1]#注意这个表达 for i in range(len(line)): if i != 0: nextline[i] = line[i-1] + line[i] line = nextline return &quot;done&quot; Iterable与Iterator，iter()Iterablepython中直接作用于for循环的对象统称为可迭代对象：Iterabale.一类是集合数据类型，如list、tuple、dict、set、str等；一类是generator，包括生成器和带yield的generator function。判断一个对象是否是可迭代对象,可以使用collections模块的Iterable类型判断。 Iterator能够被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。 iter()可以使用isinstance()判断一个对象是否是Iterator对象。可以使用iter()函数把list，dict，str获得一个Iterator对象，用next()计算。 code examples123&gt;&gt;&gt;from collections import Iterable&gt;&gt;&gt;isinstance(&quot;abc&quot;,Iterable)True 12345&gt;&gt;&gt;from collections import Iterator&gt;&gt;&gt;isinstance([],Iterator)False&gt;&gt;&gt;isinstance(iter([]),Iterator)True 12345678910#注意下面的区别&gt;&gt;&gt;isinstance((x for x in range(10)),Iterator)#返回的是一个生成器对象，不是tupleTrue&gt;&gt;&gt;isinstance((),Iterator)#tuple不是迭代器False&gt;&gt;&gt;isinstance([x for x in range(10)],Iterator)#返回一个listFalse 为什么list、dict、str等数据类型不是Iterator？ 这是因为Python的Iterator对象表示的是一个数据流，Iterator对象可以被next()函数调用并不断返回下一个数据，直到没有数据时抛出StopIteration错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过next()函数实现按需计算下一个数据，所以Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。 Iterator甚至可以表示一个无限大的数据流，例如全体自然数。而使用list是永远不可能存储全体自然数的。 惰性序列惰性计算惰性序列python中的惰性序列多数指Iterator。对于存在巨大甚至无限多的元素的序列，迭代器仅仅在迭代至某个元素时才计算该元素，在此之前或者之后，元素可以不存在或者被销毁。 意义一是这样我们就可以实现的无限序列的表示，比如全部的自然数(无穷尽)，而不需要真的在内存中计算出所有的自然数(那根本不可能，因为内存也不是无限的)，而是需要哪个数，计算到哪个数，或者需要哪些数，计算到那些数(比如前1000个)。二是在大规模数据处理中起到延迟计算的作用。当你处理大规模数据时，一次性进行处理往往是不方便的。而惰性序列就可以解决这个问题，它把计算的步骤延迟到了要实际使用该数据的时候。惰性序列可以看作是一个”流”，需要的时候从其中取一滴水。 reference博客博客2教程]]></content>
      <categories>
        <category>Languages</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[“Google机器学习速成课程”概念浏览]]></title>
    <url>%2F2018%2F03%2F13%2F%E2%80%9CGoogle%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%88%90%E8%AF%BE%E7%A8%8B%E2%80%9D%E6%A6%82%E5%BF%B5%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[摘要 ：简单总结几个最近发布的“机器学习速成课程”中的概念 正文: 随机梯度下降法（SGD）：在梯度下降法中，批量指的是用于在单次迭代中计算梯度的样本总数。到目前为止，我们一直假定批量是指整个数据集。就 Google 的规模而言，数据集通常包含数十亿甚至数千亿个样本。此外，Google 数据集通常包含海量特征。因此，一个批量可能相当巨大。如果是超大批量，则单次迭代就可能要花费很长时间进行计算。 包含随机抽样样本的大型数据集可能包含冗余数据。实际上，批量大小越大，出现冗余的可能性就越高。一些冗余可能有助于消除杂乱的梯度，但超大批量所具备的预测价值往往并不比大型批量高。 如果我们可以通过更少的计算量得出正确的平均梯度，会怎么样？通过从我们的数据集中随机选择样本，我们可以通过小得多的数据集估算（尽管过程非常杂乱）出较大的平均值。 随机梯度下降法 (SGD) 将这种想法运用到极致，它每次迭代只使用一个样本（批量大小为 1）。如果进行足够的迭代，SGD 也可以发挥作用，但过程会非常杂乱。“随机”这一术语表示构成各个批量的一个样本都是随机选择的。 小批量随机梯度下降法（小批量 SGD）是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 10-1000 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。 特征工程：从原始数据创建特征的过程。会花费实际工作中百分之70的时间。良好特征具有下列特点：1.避免很少使用的离散特征值2.最好具有清晰明确的定义3.异常的数值不要和实际数据混为一谈4.考虑随着时间的不稳定性 数据清洗：1.缩放特征值2.处理极端离群值3.分箱4.清查（遗漏值，重复样本，不良标签，不良特征值）5.了解数据 特征组合:是指通过将两个或多个输入特征相乘来对特征空间中的非线性规律进行编码的合成特征。 [A X B]：将两个特征的值相乘形成的特征组合。 [A x B x C x D x E]：将五个特征的值相乘形成的特征组合。 [A x A]：对单个特征的值求平方形成的特征组合。 机器学习训练过程问题：梯度消失较低层（更接近输入）的梯度可能会变得非常小。在深度网络中，计算这些梯度时，可能涉及许多小项的乘积。当较低层的梯度逐渐消失到 0时，这些层的训练速度会非常缓慢，甚至不再训练。ReLU 激活函数有助于防止梯度消失。 梯度爆炸如果网络中的权重过大，则较低层的梯度会涉及许多大项的乘积。在这种情况下，梯度就会爆炸：梯度过大导致难以收敛。批标准化可以降低学习速率，因而有助于防止梯度爆炸。 ReLU 单元消失一旦 ReLU 单元的加权和低于 0，ReLU 单元就可能会停滞。它会输出对网络输出没有任何贡献的 0 激活，而梯度在反向传播算法期间将无法再从中流过。由于梯度的来源被切断，ReLU 的输入可能无法作出足够的改变来使加权和恢复到 0 以上。降低学习速率有助于防止 ReLU 单元消失。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>lessons</tag>
        <tag>notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode15-3sum解题报告]]></title>
    <url>%2F2018%2F02%2F21%2Fleetcode15%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A%2F</url>
    <content type="text"><![CDATA[Given an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero. 题目Note:Elements in a triplet (a,b,c) must be in non-descending order. (ie, a ≤ b ≤ c)The solution set must not contain duplicate triplets. For example, given array S = {-1 0 1 2 -1 -4}, A solution set is: (-1, 0, 1) (-1, -1, 2) 解题思路 先把无序数组排序 固定一个数，找出其余两个数让它们的和为固定数的相反数（相加为0） 答案1234567891011121314151617181920212223242526272829303132333435363738public class Solution &#123; List&lt;List&lt;Integer&gt;&gt; ret = new ArrayList&lt;List&lt;Integer&gt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] num) &#123; if (num == null || num.length &lt; 3) return ret; Arrays.sort(num); int len = num.length; for (int i = 0; i &lt; len-2; i++) &#123; if (i &gt; 0 &amp;&amp; num[i] == num[i-1]) continue; find(num, i+1, len-1, num[i]); //寻找两个数与num[i]的和为0 &#125; return ret; &#125; public void find(int[] num, int begin, int end, int target) &#123; int l = begin, r = end; while (l &lt; r) &#123; if (num[l] + num[r] + target == 0) &#123; List&lt;Integer&gt; ans = new ArrayList&lt;Integer&gt;(); ans.add(target); ans.add(num[l]); ans.add(num[r]); ret.add(ans); //放入结果集中 while (l &lt; r &amp;&amp; num[l] == num[l+1]) l++; while (l &lt; r &amp;&amp; num[r] == num[r-1]) r--; l++; r--; &#125; else if (num[l] + num[r] + target &lt; 0) &#123; l++; &#125; else &#123; r--; &#125; &#125; &#125; &#125; Note这个题目要注意得出的结论可能出现重复的可能，另外要考虑的所有特殊情况如下： 结果重复 输入数组长度不够 输入数组为空另外，在搜寻三个数使得其和为0的思路上，不能采取用三个循环的思想，这样会导致时间复杂度很高。可以固定其中的一个数，设置两个指针，让这两个指针移动计算,降低时间复杂度。]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>algorithms</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04安装OpenCV3.3教程]]></title>
    <url>%2F2017%2F12%2F22%2FUbuntu16.04%E5%AE%89%E8%A3%85OpenCV3.3%2F</url>
    <content type="text"><![CDATA[摘要：搭建OpenCV3.3的过程 安装依赖环境1234567$ sudo apt-get install build-essential libopencv-dev$ sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev$ sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev # 处理图像所需的包$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev liblapacke-dev$ sudo apt-get install libxvidcore-dev libx264-dev # 处理视频所需的包$ sudo apt-get install libatlas-base-dev gfortran # 优化opencv功能$ sudo apt-get install ffmpeg 获取源代码1$ git clone https://github.com/opencv/opencv.git 编译源代码123456789$ cd opencv$ mkdir build$ cd build$ cmake ..$ make -j 10 替换旧版本1$ sudo make install 编译出错的处理执行cmake的时候，可能会出现下面的错误信息：12345678910CMake Error at CMakeLists.txt:11 (message): FATAL: In-source builds are not allowed. You should create separate directory for build files.-- Configuring incomplete, errors occurred! 则是在代码根目录下直接执行过 cmake，导致根目录下生成了 CMakeCache.txt，需要删除 CMakeCache.txt再次执行编译即可。]]></content>
      <categories>
        <category>Operating Systems</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python字符串切片操作]]></title>
    <url>%2F2017%2F11%2F26%2Fpython%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%87%E5%8F%96%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[详述在python中如何切片？ 字符index首先需要明白字符的index是什么？对于一个字符串：1&gt;&gt;&gt;str = &quot;abcdefg&quot; 其各个字符的index分别为 0 1 2 3 4 5 6如果用负数表示，就是 -7 -6 -5 -4 -3 -2 -1 取字符串中第几个字符根据index获取即可：12&gt;&gt;&gt;str[2]a 字符串分割表达式 str[a:b]，表示从字符串index为a的字符，截取到index为b-1的字符12&gt;&gt;&gt;str[1:2]b 步长截取str[a:b:c]:表示从第a个字符串开始，截取到第b个字符的前一个为止。不过这里要&lt;\font color = ‘red’&gt;注意&lt;\font&gt;:当c小于0时，字符串的index是反向数的，也就是从index为b的到index为a+1的字符，每隔-c个字符取一个字符。比如：12&gt;&gt;&gt;str[3:1:-1]dc]]></content>
      <categories>
        <category>Languages</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Can you fool AI with adversarial examples on a visual Turing test?》论文笔记]]></title>
    <url>%2F2017%2F11%2F21%2F%E3%80%8ACan-you-fool-AI-with-adversarial-examples-on-a-visual-Turing-test-%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Xu X. Can you fool AI with adversarial examples on a visual Turing test?[J]. 2017. citationXu X. Can you fool AI with adversarial examples on a visual Turing test?[J]. 2017. introduction先介绍VQA(Visual Question Answering)：也叫做visual Turing test，也就是让机器学习模型回答一个关于图片的用自然语言表述的问题。可以通过回答的正确度判断模型的效果。VQA问题是深度学习的引用问题中比较复杂的一个分支，涉及的面也比较广，但是同样也会受到对抗样本攻击的影响。在这篇文章中，研究目标就是利用目标对抗攻击，让模型生成特定的question-answer pair。（这是对VQA系统进行对抗攻击的第一次尝试） content and contributions本文的研究内容如下： 1. 实验证明了一个训练好的VQA模型也会被对抗攻击影响。这里的攻击设定为白盒攻击：即是已知这个VQA模型的结构和权重。 2. 进一步用对抗样本攻击目前效果最好的VQA模型，发现了两个现象： 1) 如果目标question-answer对出现频率越大，内容更加想关，回答更加有意义，那么以这个“问答对”作为目标构造的对抗样本成功率更高。（这个现象叫做language prior，也比较好解释，模型往往会选择更加有意义，关联性更强的问答组合作为最终的结果。这种现象在针对具有显示推理特征的VQA模型时更加明显） 2) 在VQA问题中构造的对抗样本具有可移植性，说明可以用这个方法构造黑盒攻击。 3. 研究在两种训练好的模型的上进行了对抗攻击，一种模型是 bilinear fusion model MCG（结合问题和图片的特征预测答案），一种是组合模型NMN（建立依赖问题的网络布局，让这个网络处理图片得到预测答案）。比较之下，后者更不容易受到对抗样本的影响，说明了这种结构的模型更加稳定。 研究的contribution如下： 1. 第一个提出针对VQA模型的对抗攻击 2. 提出生成对抗样本的新算法 3. 实验发现了当目标问答对出现频率比较高时，VQA模型存在目标对抗样本。且这种对抗样本有可移植性 4. 发现了language prior现象，即是当以一些问答对作为攻击目标时，效果很差 5. 发现组合的神经网络模型更加稳定，这种增强模型稳定性的结构可以作为提升模型鲁棒性的参考。 backgroundVQA所谓的VQA，也就是Given an image and a natural language question as an input, the goal of VQA is to predict a natural language answer. 它的应用很广，研究中用到的组合VQA和非组合VQA如下： non-compositional以[A. Fukui, D. H. Park, D. Yang, A. Rohrbach, T. Darrell, and M. Rohrbach, “Multimodal compact bilinear pooling for visual question answering and visual grounding,” in Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2016.]提出的MCB方法为例。这个方法是先用两个网络模型$f_1$和$f_2$分别映射原始图片和question。它依赖的模型是一个整体结构，可以直观理解为输入端问题和图片到输出端答案的映射，输出就是计算出的$argmax_j(softmax(Wu^.))$。 compositional这种组合模型，比如[R. Hu, J. Andreas, M. Rohrbach, T. Darrell, and K. Saenko,“Learning to reason: End-to-end module networks for visual question answering,” in Proc. of ICCV, 2017.]提出的方法。这种组合可以解释为两步：首先计算根据问题和图片的表达式$u_i^.$；然后基于问题question和$u_i^.$预测答案。也就是这种模型有两步操作，两步依次执行最终给出预测答案。而在Hu等人的研究中，将这两步又拆分成了九个module，比如找到图片中的相关区域算为一个module。这种不同module组合形成的模型，也就叫做组合模型。adversarial examples、Transferability and Black-box Attacks的相关背景比较熟悉，不再赘述 model details研究有几个前提： 1. **白盒攻击**，即是攻击者知道模型的结构和网络权重。因此，攻击者可以计算模型的输出关于输入的梯度值。而本实验就是在这个假设的前提下进行的。利用这个梯度信息，就可以生成降低模型准确度的对抗攻击。 2. 目标模型没有任何防御策略：并不会影响本实验的典型性，因为 most existing defense proposals are either not properly evaluated and vulnerable to strong attacks, or only designed for black-box attacks 。 3. 攻击形式是指定目标的target attack：原因一是因为非目标攻击威胁不大，其二是因为真实攻击者用目标攻击往往能产生更好的攻击效果。 4. attack success rate：攻击成功率用来衡量生成的对抗样本，也是一个标准测量方法。 5. 提高模型的输出概率：因为模型是根据输出的概率向量来预测问题的答案，如果这个概率比较低，就容易被防御策略检测出来，因此，提高对抗样本的输出概率值，也能反映攻击的有效性。 algorithmsVQA模型定义为$f_\theta(I,Q)$,$\theta$是模型的参数，I是输入图片，Q是输入问题，f的结果是预测的答案概率值。与传统将VQA问题视作分类问题不同，作者将对这个模型$f_\theta$攻击抽象为，构建一个对抗样本图片$I^{adv}$,让模型的输出为问答对$(Q^{target},A^{target})$的概率最大，即是$$f_\theta(Q^{target},A^{target})=A^{target} s.t.d(I^{adv},I^{ori})\le B$$整体的优化问题即是：$$argmin_{I^{adv}}L(J_\theta (I^{adv},Q^{target}),A^{target}) s.t.d(I^{adv},I^{ori})\le B$$ 本文提出的算法优化，主要就是用一种替代目标函数来逼近优化函数，从而提升效率。$$\xi(A^{predict})= L(J_\theta (I^{adv},Q^{target})+\lambda 1.l(A{target}\ne A^{predict}.(\tau-L(J_\theta(x,Q^{target},A^{predict})))+\lambda _2.ReLU(d(x,I^{ori})-B+\epsilon)$$整体的算法如下： conclusion文章的结论有三个方面： 1. 目标对抗攻击（本文是目标对抗攻击）的成功率主要受到所选择的question-answer pair的类别的影响，跟参考图片的选择关系不大。 2. 发现了language prior phenomenon，给针对特定question-answer pair能产生对抗样本提供了一种可能的解释。 3. 发现组合VQA模型结构更加稳定。 这篇文章对对抗攻击的创新主要就是1）应用在了VQA新场景下2）优化目标函数的方法比较新颖]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
        <tag>papernotes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Delving into adversarial attacks on deep policies》论文笔记]]></title>
    <url>%2F2017%2F11%2F19%2F%E3%80%8ADelving-into-adversarial-attacks-on-deep-policies%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Kos J, Song D. Delving into adversarial attacks on deep policies[J]. 2017. citationKos J, Song D. Delving into adversarial attacks on deep policies[J]. 2017. introduction这篇文章是关于深度增强学习策略网络模型的对抗攻击研究。主要的研究内容有： 1. 比较对抗样本和随机噪声的攻击性 2. 提出了一个基于值函数的可以提高对抗样本生成效率，减少实现一个成功的对抗攻击时需要“入侵”目标模型的次数。 3. 研究如何重新训练来增强模型对随机噪声和FGSM攻击的稳定性。 study content这篇文章contribution和objects都是三个： 1. 比较了随机噪声和对抗样本对深度增强学习策略模型deep reinforcement learning (DRL) 的影响。发现了采用这种DRL策略的模型也容易受到对抗样本的攻击。 2. 提出了利用增强学习策略中的值函数来引导攻击者选择在原始样本中添加对抗扰动的时间。（这种构造对抗样本的方法相比于以前在图片分类等等任务中，间隔固定时间添加对抗扰动的策略更复杂一些，但是作者发现这样效率更高） 3. 通过re-training可以增强策略的稳定性。初步结果表明，通过re-training，agents可以对FGSM生成的对抗样本和随机噪音都更加稳定。同时，作者也研究了这种提高的稳定性是否会根据扰动的不同规模和不同种类而发生改变。发现这种方法并不能增强模型对其他攻击类型的防御能力。 对第二个研究目标，作者提出了三个方法来探究是否减少了添加perturbation的频率也能生成有效的对抗样本：1)每隔N步给原始样本注入一次扰动，在间隔中计算扰动但是不添加到样本中；2)每隔N步计算一次扰动，并加入到数据样本中；3)引入一个“值函数”，计算什么时候添加扰动效果最好，确保添加的时机让这个值函数处于阈值。 experimental evaluation这部分首先是介绍两个概念，A3C算法是一个应用在深度增强学习任务中的比较成功的算法：通过策略权值的异步更新权值。[Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy P Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning, 2016.]另一个概念是FGSM，也就是 Goodfellow等人提出的比较典型的对抗样本生成算法。实验首先在base-line的情况下得到了一个在Atari Pong任务中训练得到的增强模型，然后设定FGSM中的对抗扰动规模超参数$\epsilon$，并得到对抗样本。同时从均匀分布$unif(0,β)$随机取样得到随机噪声。实验结果上，第一个任务没有什么值得注意的。对于第二个任务，这里的N设为10，实验结果如图：在$\epsilon$为0.005，扰动规模一定的情况下，第一个方法生成的对抗样本效果不如每隔10步计算一次perturbation得到的样本（方法2）效果更好。同时，用一个让值函数大于一个阈值时才加入对抗扰动的策略，如下图：红色的线表示值函数的变化，这个值函数即是增强学习的反馈值。当这个函数大于一定值的时机加入对抗扰动，即是这个扰动也更加贴近模型训练时的反馈。最终的结论是，在增强学习背景下，用基于值函数得到的对抗样本，尽管更加复杂，但是也更加高效，得到的样本对抗性更强。 conclusion今年才开始有将对抗样本应用到增强学习领域的相关研究。相比于《Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks》，，前者是通过改变对抗样本训练策略，将对抗样本的训练和增强学习的反馈结合起来，得到更高效且效果更好的攻击样本。后者针对的策略是Deep Q-networks，并且是利用了对抗样本的transferability。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
        <tag>papernotes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Generative Face Completion》论文笔记]]></title>
    <url>%2F2017%2F11%2F18%2F%E3%80%8AGenerative-Face-Completion%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Title: Generative Face CompletionAuthors: Li, Yijun; Liu, Sifei; Yang, Jimei; Yang, Ming-HsuanPublication: eprint arXiv:1704.05838Publication Date: 04/2017Origin: ARXIVKeywords: Computer Science - Computer Vision and Pattern RecognitionComment: Accepted by CVPR 2017Bibliographic Code: 2017arXiv170405838L citationLi Y, Liu S, Yang J, et al. Generative Face Completion[J]. 2017. Content论文用深度生成模型实现了一个高效面部补全算法。与传统从已给数据集中搜寻相似图片块儿来进行补全和合成残缺图片的方法不同，作者是直接使用一个神经网络来合成残缺部分的内容。整个模型由三部分构成：a reconstruction loss、two adversarial losses、a semantic parsing loss。 a) 论文目的： 传统以复制-粘贴的方式来进行图片补全在背景填充方面效果不错，但在面对填充脸部图片这种目标图片比较独特时却效果不佳。作者于是想用深度生成模型构建一个有效的目标补全算法，能不需要参照外部数据集快速完成对图片的补全。 b) 论文贡献： 首先提出了一个深度生成补全图片补全模型，这个模型通过encoding-decoding 生成器、两个对抗判别器来合成用随机噪声遮挡的部分；其次对挑战性的脸部补全任务进行处理，并且实现提出的模型能够根据学习到的目标特征，产生整体比较和谐的图片；最后，作者证明了生成semantic parsing部分的有效性。 c) 模型结构： 整体结构如下图：生成器G：结构有encoder层、两个全连接层和decoder层，输入的残缺图片通过encoder层映射成隐藏特征，然后再通过decoder层得出生成的图片。里面的encoder层是两层以上卷积层加上一层以上池化层，decoder层与encoder对称。 判别器D：如果只有一个生成器，那么生成的图片将会非常模糊，只有一个粗略的轮廓。因此，采用了两个判别器来对生成图片的细节进行完善，使得生成的图片更加真实。其中，有两个判别器：local discriminator和global discriminator。其中，局部判别器是为了让生成器生成图片中补全的部分更加真实，而整体的判别器是为了让整个生成的图片看起来更加真实。 Semantic Regularization：前面的两个部分其实就是原始GAN的变形，作者加上后面这一部分的原因是，前面生成的图片虽然整体上轮廓清晰比较真实，但是看上去却不像是人脸的图片。如下图： 加上autoencoder结构的semantic parsing network之后，生成的图片会更加和谐： d) 损失函数： 因为模型分为三部分，因此损失函数也有三部分： 整体的损失函数如下： $$L = L_r + λ_1L_{a1} + λ_2L_{a2} + λ_3L_p$$ 其中， ①$L_r$是生成器的损失，就是输入与输出的二阶范数。 ②$L_{a1}$与$L_{a2}$是两个判别器的损失，其形式跟GAN的判别器损失大同小异： ③Lp就是semantic parsing network的损失，就是简单的softmax层损失。 它们前面的参数是用来平衡各个部分损失不同影响的。 e) 训练步骤： 与我上一篇看的pix2pix两步走的训练步骤类似，作者采用了三步训练： ①用生成器直接训练，得到模糊的结果； ②用局部判别器损失来微调生成模型； ③联合整体判别器和意义转化网络损失来调整生成模型参数。 这个方法据说可以避免训练开始阶段判别器的作用过强。和我毕设的预训练类似。 f) 数据集选择： 作者用到了两个数据集，一个是Celeb A，一个是Helen test数据集，这两个数据集都是面部图片的集合，并且后者还有segment label。以后做实验可以考虑使用。 g) 实验结果： 作者将自己模型产生的结果与CE模型产生的结果进行直接对比，并用了三种测量标准测试，证明作者提出的模型效果更好。作者还做了遮挡不同面积的图片，来观察结果的效果，并得出在size是32×32时效果是最好的，因为此时的遮挡面积刚好是面部器官的一部分，比如半只眼睛。 心得体会a) 训练步骤也有一个预训练部分（只训练生成器），和我毕设中对生成器预训练类似。以前一直以为只是用来让后面的训练时间更短，论文中提到这样训练也可以避免在训练的初始阶段，判别器的作用太强，影响训练效果。 b) 论文对GAN的变形方式值得借鉴，采用两个判别器的模型分别完成对局部和整体的训练，思路很好。d） 作者在模型的最后部分还采用了一个semantic parsing networks结构，这个部分能让整体的输出更加和谐，具体的参考论文还没了解，因此其原理了解很模糊。e) 论文的目的是对独特的目标图片进行补全，以面部图片为例，但是论文一直是以脸部图片作为实验训练集，如果能加入其他比较独特的图片，比如建筑、动物等，可能说服力会更强。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
        <tag>papernotes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《NO Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles》论文笔记]]></title>
    <url>%2F2017%2F11%2F02%2F%E3%80%8ANO-Need-to-Worry-about-Adversarial-Examples-in-Object-Detection-in-Autonomous-Vehicles%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[citationLu J, Sibai H, Fabry E, et al. NO Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles[J]. 2017. Introduction这篇文章是在《Adversarial examples in the physical world》（A. Kurakin, I. J. Goodfellow, and S. Bengio. Adversarial examples in the physical world. CoRR, abs/1607.02533, 2016.）的基础上的进一步研究。因为在传统的对抗攻击构建过程中，对抗perturbation直接和数字图片叠加，作为神经网络模型的输入。Kurakin等人的研究中，对抗的perturbation被生成之后，如果和原始数据叠加后，不是直接作为模型的输入，而是通过相机拍摄的方式输入到模型中。Kurakin等人的研究模拟了实际physical场景下的对抗攻击场景，并且证明了对抗扰动在从对抗样本到拍照后的对抗样本的转化过程中，虽然有相机的noise，仍然是具有对抗性的。同时，也因为《Concrete Problems for Autonomous Vehicle Safety: Advantages of Bayesian Deep Learning》（Mcallister R, Gal Y, Kendall A, et al. Concrete Problems for Autonomous Vehicle Safety: Advantages of Bayesian Deep Learning[C]// Twenty-Sixth International Joint Conference on Artificial Intelligence. 2017:4745-4753.）中应用对抗攻击到自动汽车驾驶问题中的挑战问题。另一个相关研究是《Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition》（M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter. Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS ’16, pages 1528–1540, New York, NY, USA, 2016. ACM. ），本文的研究证明了在面部识别的实际应用中，通过构建对抗样本，不论是否已知面部识别模型的结构（黑盒或者白盒攻击），都可以在把实际拍摄脸部照片作为模型输入的情况下，极大地影响识别的结果。上述研究都给神经网络模型的实际应用带来了很多concern。 本文的研究则是通过一些实验，证实物理世界中的对抗攻击在多种距离和角度效果不佳。在汽车驾驶中交通标示识别实验中，大部分的在汽车行进过程中拍摄对抗样本都被分类模型正确分类。 methods论文的实验方法是使用多种攻击方法测试得到训练好的模型的稳定性。并且训练的模型有两种不同的结构。所用的数据集是widthlengthdepth的三维向量。所用的攻击方法有： Goodfellow提出的FGSM[I. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.] Kurakin等人提出的迭代FGSM[A. Kurakin, I. J. Goodfellow, and S. Bengio. Adversarial examples in the physical world.CoRR, abs/1607.02533, 2016.] Szegedy 等提出的L-BFGS方法[C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan,I. Goodfellow, and R. Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.] 与一般的对抗攻击研究只针对分类问题不同，本文所攻击的目标模型也采用了探测器模型：the YOLO multiple object detector [J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 779–788, 2016.]本文中classifier与detector的不同之处在于： classifier使用交叉熵损失函数，衡量输入图片真正的标签($y_{true}$)和输出的one-hot标签($y_{fool}$)的差别。 detector中，模型的输出是向量$p_{output}$ ，但是输入样本却没有one-hot标示的标签（因为输入的数据是即时的，一直变化的）。因此实验设置是输入的标签的维度和输出一样，都为 $ l_{p_{output}} $ 。 本文的实验方法与前面提到的攻击算法研究中修改图片不同，关注的是在物理世界的攻击，也就是打印应用这些攻击之后的图片并测试目标模型的稳定性。应用到实际场景时，作者考虑了拍摄相机与目标的距离和拍摄角度的变量影响。 experimental results 分析生成的对抗样本结果首先是针对detector目标模型生成的对抗样本：对比针对traffic sign classifier生成的对抗样本：可以发现前者的密度更低。从直观理解也很容易，因为密度越高的对抗扰动可以让探测器的实时监测扰动更加困难。 整体的对抗样本稳定性的实验结果DR%代表这个stop标志被识别的概率。表格中的Ori指的是完整的图片，Crop则指的是裁剪出只有交通标志的部分。表格的左边是对抗样本在直接作为模型输入时的对抗效果，右边是在现实场景下的实验结果。从表格可以得出下面的结论： 只关注标志本身的，经过裁剪之后的对抗样本效果更好 在实际应用场景下，对抗样本的对抗性会随着距离的增加而减弱，模型的识别准确率会更高 从结果来看对抗攻击方法的效果，L-BFGS整体要差于FGSM方法。 而这篇文章主要关注的变量，也就是对样本效果影响最大的变量，就是距离的变化。从实验结果中最后两列可以看出，随着距离的增加，对抗样本的对抗性衰减十分明显。但是这种情况也有例外，这说明了对抗扰动的效果在随着距离而变化。因此，在实际应用场景下，探测系统/分类模型只需要调整距离和角度，是可以实现正确识别输入样本的。 conclusion此外，这两天的对比看文章，和前几天看的《Standard detectors aren’t (currently) fooled by physical adversarial stop signs》比较相似，这一类的文章的内容只是通过实验推翻了前面研究的实验结果。不过本文的观点显然也有一定的缺陷，因为在很多场景下，人们允许的失误率阈值会比较低，甚至不能容忍模型的识别错误。本文只是说明了对抗的效果没有Kurakin等人的研究中那么显著而已。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
        <tag>papernotes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Standard detectors aren’t (currently) fooled by physical adversarial stop signs》论文笔记]]></title>
    <url>%2F2017%2F10%2F31%2F%E3%80%8AStandard-detectors-aren%E2%80%99t-currently-fooled-by-physical-adversarial-stop-signs%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[citationLu J, Sibai H, Fabry E, et al. Standard detectors aren’t (currently) fooled by physical adversarial stop signs[J]. 2017. IntroductionEvtimov等人在《Robust Physical-World Attacks on Machine Learning Models》提出了RP2算法，可以构建对抗样本，通过添加精心设计的扰动，使交通标示探测器的结果错误，达到对抗攻击的目的。但是本文的作者认为，Evtimov等人在构建对抗样本的实验过程中，对原始图片进行了两种处理：一是对原始图片进行了剪切，二是重新设定了图片的尺寸。本文的作者认为，这样的处理会让模型在训练时能有效的适应视觉角度和规模变化，但是处理之后就消除了这种训练结果。同时，增加的对抗扰动也会有这种视觉角度和规模的变化，因此是否有效需要通过实验验证。不止这种视觉角度和图片规模的改变，针对探测器的对抗攻击也要考虑到大量参数变化（scale; view angle; box shift inside the detector;illumination;等）。另外，对一个classifier和detector进行的对抗攻击应该是有区别的，后者因为不能准确地估计探测边界，所以构造对抗样本也会更加困难。最后，本文中用（YOLO and Faster RCNN）[J. Redmon and A. Farhadi. Yolo9000: better, faster, stronger.arXiv preprint arXiv:1612.08242, 2016.][S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems, pages 91–99, 2015.]训练得到的探测器进行测试，发现不会受到对抗攻击的影响。 Difference between Classifiers and Detectors 两者不会明显区分分类边界，因为对于探测器来说，确定物体边界十分困难。（The key feature of detection systems is that they tend not to get the boxes exactly right） 原因分析： Close cropping can remove scale and translation effects Low resolution boxes Cropping and variance Cropping and context experimental resultsEvtimov等人的实验主要是两个方面，一种是poster attacks (the stop sign is covered with a poster that looks like a faded stop sign) ，一种是 sticker attacks (the attacker makes stickers placed on particular locations on a stop sign)，因此本文的对照实验采用同样的攻击方式。 首先是在YOLO探测模型上的探测对抗结果：然后是在Faster RCNN探测模型上的探测结果：从这两个结果上来看，原来的对抗攻击的成功率已经下降到0，说明了Evtimov等人提出的对抗样本构建方法失效了。 conclusion探测器并不能声称完全免疫物理对抗攻击，然而目前没有证据证明物理对抗样本能对detector产生效果。这篇文章实验主要就是实验部分，通过实验证明了Evtimov的研究的不充分，说明了实际中，对探测器的攻击的存在性还待进一步研究。找到这种攻击的存在还有很大的挑战。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
        <tag>papernotes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Robust Physical-World Attacks on Machine Learning Models》论文笔记]]></title>
    <url>%2F2017%2F10%2F30%2F%E3%80%8ARobust-Physical-World-Attacks-on-Machine-Learning-Models%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Title: Robust Physical-World Attacks on Machine Learning ModelsAuthors: Evtimov, Ivan; Eykholt, Kevin; Fernandes, Earlence; Kohno, Tadayoshi; Li, Bo; Prakash, Atul; Rahmati, Amir; Song, DawnPublication: eprint arXiv:1707.08945Publication Date: 07/2017Origin: ARXIVKeywords: Computer Science - Cryptography and Security, Computer Science - LearningBibliographic Code: 2017arXiv170708945E citationEvtimov I, Eykholt K, Fernandes E, et al. Robust Physical-World Attacks on Machine Learning Models[J]. 2017. 概述&emsp;最近的研究中，许多对抗样本构造方法在真实自然世界效果不好。已有的对抗攻击研究在现实世界中，往往不能使分类模型误分类，或者只在非常有限的情况比如复杂原始图像经修改后打印出来才能达到对抗攻击的目的。&emsp;本论文要点如下： 提出Robust Physical Perturbations(RP2)算法，能产生鲁棒且自然有效的对抗扰动。 使用RP2算法用两种方式构造对抗攻击：– subtle perturbations：对整个标志进行微小的、很难探测到的改动。把整个受到攻击后的图片打印后覆盖到原标志上面，尺寸和原图一样。– camouflage perturbations：以涂鸦或艺术画的形式对原图进行可见的改变。攻击者直接将扰动攻击打印出来，然后贴到已经存在的标志上面。 因为目前缺乏衡量自然界对抗攻击效果的标准方法，因此论文提出了一种评估方法。 Introduction 提出在physical world也有效的对抗样本生成算法的原因： 一方面，《No need to worry about adversarial examples in object detection in autonomous vehicles》（J. Lu, H. Sibai, E. Fabry, and D. Forsyth, “No need to worry aboutadversarial examples in object detection in autonomous vehicles,” arXivpreprint arXiv:1707.03501, 2017.）研究FGSM和L-BFGS算法，发现生成的路面警示标志的对抗样本在多种观察条件下效果很差（改变角度和距离）。另一方面，《Synthesizing robust adversarial examples》（A. Athalye and I. Sutskever, “Synthesizing robust adversarial examples,”arXiv preprint arXiv:1707.07397, 2017.）说明可以通过更好的对抗样本算法来生成扰动图片，在图片被打印出来用相机来观察时在各种情况下都是鲁棒的。 在针对分类的对抗攻击可行性上面，仍然有许多遗留问题。首先，给目标的背景增加扰动不可实现。第二，相比于目前所用的复杂图片，将扰动隐藏在像路标这种简单的目标中是更加困难的。第三，对于难以感知的扰动， 还有额外的物理上的限制，因为轻微的扰动可能让相机在多种自然情况下不能获取这些扰动信息（如长距离和多角度情况下）。 本论文的主要目的：对真实世界目标构建robust且轻微的扰动是否可行。 需要解决的问题： 汽车中的相机与路标的距离一直在变化 汽车中的探测相机与路标的角度一直在变化 光线强弱变化 在路标或者汽车上的遮挡物 Related work这一部分先总结了三种对抗样本的生成方法： （I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” arXiv preprint arXiv:1412.6572, 2014.） 提出的FGSM方法。 （N. Carlini and D. Wagner, “Towards evaluating the robustness of neural networks,” in Security and Privacy (SP), 2017 IEEE Symposium on.IEEE, 2017, pp.39–57.）提出的基于迭代优化算法在一定限制下查找perturbation。 （S.-M. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and P. Frossard, “Universal adversarial perturbations,” arXiv preprint arXiv:1610.08401, 2016.）提出的能应用到黑盒攻击中的无目标攻击，在各种对抗图片生成上都有效果。 这三种方法都假设能得到输入向量的数字层面的特征，这在自然情况自动汽车背景下不适用。同时，它们都需要perturbation程度比较小且不可见，因为直接以数字向量作为神经网络输入时，这种微小的perturbation不会被破坏。但是，如果把修改后的样本打印到纸张上，那么这种在自然界重建perturbation的过程就会在每个步骤造成信息的损失。因此（J. Lu, H. Sibai, E. Fabry, and D. Forsyth, “No need to worry about adversarial examples in object detection in autonomous vehicles,” arXiv preprint arXiv:1707.03501, 2017.）证实了这些方法在真实世界中效果不好。 然后介绍了本论文中两种攻击方式的由来： Subtle Perturbations:（A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial examples in the physical world,” CoRR, vol. abs/1607.02533, 2016. [Online].Available: http://arxiv.org/abs/1607.02533）里面修改控制图片的数字表示，然后将图片打印出来，通过手机相机来读取图片并作为分类器的输入。 Camouflage Perturbations：（“Best practices for developing with kairos,” 2017. [Online]. Available:https://www.kairos.com/docs/api/best-practices）和（M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, “Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition,” in Proceedings of the 23rd ACM SIGSAC Conference on Computer and Communications Security, Oct. 2016. [Online]. Available: https://www.ece.cmu.edu/~lbauer/papers/2016/ccs2016-face-recognition.pdf）中显示了有着对抗perturbation的眼睛能够欺骗面部识别系统，与本论文的目的一致——通过重建物理目标，给已经存在的目标加入新的对象能够欺骗深度神经网络。与面部识别的不同之处仅仅在于环境不同。 Experiment数据集：LISA数据集，包含47种不同的路标图片，在本实验中重设尺寸为32×32 实验用TensorFlow工具构建分类器，神经网络结构为：三成带有全连接层的卷积层。最终的分类器准确率为91%。攻击过程的选择，本实验只能修改测试集数据，即是evasion attacks。攻击流程： 1. 得到没有对抗perturbation的干净目标路标图 2. 预处理路标图（维度等）将之作为分类器的输入 3. 用攻击算法处理分类器和提取的路标图片 4. 用映射函数在路标上输出相应的对抗perturbation的物理位置 5. 构建数字对抗perturbation，并基于上面函数的输出将这个改动应用到物理目标中。 自然对抗perturbation的评估方法： 受自然情况下环境条件、空间限制、样本构建误差、维度变化和不可探测的物理限制等影响，在评估对抗样本效果时，论文考虑了三个主要的方面：距离、角度和维度。 Robust Physical Perturbations(RP2)算法： 是一种优化的扰动生成方法，在untarget对抗攻击时，目标函数为 $$argmin_λ||δ||p − J(fθ(x + δ),y)$$ 即是让加入扰动后的输出损失越大越好。 在target对抗攻击时，目标函数为 $$argminλ||δ||p + J(fθ(x + δ),y_0)$$ 即是让加入扰动后输出损失与特定目标差别越小越好。 其中λ都代表对扰动规模的限制。 Future work 因为论文用的交通标志比较有限，考虑使用更多的交通标志完成target classification attack。 增加一种扰动补偿的步骤到已有的对抗攻击生成流程中。 在更多现实场景下测试算法，比如标志遮挡。 因为自动汽车的视觉次级系统主要有两个组成部分：一个是目标探测器，一个是分类器。本文主要是研究了对分类器的攻击，但是对目标探测器的攻击也可以达到攻击目的。（P. Viola and M. Jones, “Rapid object detection using a boosted cascade of simple features,” in Computer Vision and Pattern Recognition, 2001.CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on, vol. 1. IEEE, 2001, pp. I–I.）和（P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan, “Object detection with discriminatively trained part-based models,” IEEE transactions on pattern analysis and machine intelligence, vol. 32, no. 9,pp. 1627–1645, 2010.） 问题 还没有实验证明，对原始数据perturbation的程度应该是多少才不至于被人类观察者注意到。 构建perturbation的时候，如果只讲这种对抗攻击的信息体现在黑白灰度层面而不是彩色，可能会让生成的对抗样本更加robust。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
        <tag>papernotes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Concrete Problems for Autonomous Vehicle Safety:Advantages of Bayesian Deep Learning》论文笔记]]></title>
    <url>%2F2017%2F10%2F29%2F%E3%80%8AConcrete-Problems-for-Autonomous-Vehicle-Safety-Advantages-of-Bayesian-Deep-Learning%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Rowan McAllister, Yarin Gal†, Alex Kendall, Mark van der Wilk, Amar Shah, Roberto Cipolla, Adrian Weller†Department of Engineering, University of Cambridge, UK† also Alan Turing Institute, London, UK，Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17) CitationMcallister R, Gal Y, Kendall A, et al. Concrete Problems for Autonomous Vehicle Safety: Advantages of Bayesian Deep Learning[C]// Twenty-Sixth International Joint Conference on Artificial Intelligence. 2017:4745-4753. ##概要##这篇论文主要讲的是安全的实际应用。在自动汽车领域，软件方面就是通过一系列流程，将各种传感器的输入链接到发动机的输出上。而在这种传播过程中，如果有信息的损失就会有差错（比如将80%几率不会相撞直接判断为不会相撞） 。各个部分的差错也会被依次累积传递下去，最终输出错误的结果。同时，要让客户信任自动汽车，并使用这个系统，必须在三个方面开展研究：自动汽车的安全性（通过量化每个部分输出的不确定性，并且将这个不确定性也顺着流程传递下去）、可解释性（向客户解释自动汽车所看到的，并且为什么作出一系列决策，从而让客户安心）、顺从性（指的是让客户在自动汽车驾驶过程中维持对汽车的控制）。 自动汽车软件系统由多个单独的子系统组合而成。主要有object detection and localisation components负责场景识别，scene prediction component负责根据场景来预测汽车的运动，最后，decision components做出汽车最终动作决定，控制发动机完成汽车驾驶。而目前，这三个方面渐渐使用深度学习工具搭建，比传统的方法在多个任务上具有更好地效果。但是，基于深度学习的自动汽车软件系统也有许多挑战。正如容易受到对抗样本的干扰，从而做出错误的决断。 ##提升自动汽车可靠性的三个方面##Safety在自动汽车的软件部分由多个单独的部分联合构成。为了提升系统的安全性，提升每个部分是必要但不是充分的，因为单个部分的错误会随着整体流程而累积。因此，为了避免最终输出的结果出现错误，应该把每个部分的错误和不确定性都体现在其输出上，最终的输出也就体现了所有部分的不确定性。而传播这种不确定性主要有两种方法：一种是贝叶斯概率理论，一种是ensembling。而利用贝叶斯工具掌握这种不确定性在传统自动汽车研究中已经使用过。但是与深度学习系统结合，还存在很多困难。因此，论文提出了贝叶斯深度学习（Bayesian Deep Learning）模型。 如上图，利用BDL模型的自动汽车，可以得到汽车有可能会相撞的结果，从而采取相应的停车措施。而在自动汽车的各个部分，都采用BDL工具。 ##Interpretability##解释性算法能让客户掌握自动汽车作的每一个决策以及得到的输出。这种掌握可以采取三种形式：图像、文字语言或者听觉。这样，每一个客户对自动汽车整个系统就有了比较直观的理解。比如，可以通过在路程中询问：“你为什么突然左转”，自动汽车就会给出作出左转决策的原因。而对这个问题的探索，有两个技术方面：model saliency 和 auxiliary outputs。前者根据图片显示与系统决策关联最显著的部分；后者是根据传感器的输入得到辅助输出，显示系统的控制信息。 Compliance这部分即是让自动汽车也能服从人的命令，而不是一味按照自己的算法模型作出决策。这样也能让客户感觉可靠。而自动汽车服从命令主要是按照两个方面：passenger reassurance和 law abiding。前者是根据乘客的需要改变决策，后者是所有的决策要在法律允许的范围内，要满足社会常识的前提。 这篇论文和对抗攻击的关联不大，只是给针对各种攻击的defence提供了一种利用贝叶斯公式传递不确定性的思想。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
        <tag>papernotes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[范数总结]]></title>
    <url>%2F2017%2F10%2F26%2F%E8%8C%83%E6%95%B0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[关于范数的知识总结 什么是范数 范数是一种强化了的距离概念。他在定义上比距离多了一条数乘的运算法则。数学上，范数包括向量范数和矩阵范数。向量范数表征向量空间中向量的大小，矩阵范数表征矩阵引起变化的大小。一种非严密的解释就是，对应向量范数，向量空间中的向量都是有大小的，这个大小如何度量，就是用范数来度量的，不同的范数都可以来度量这个大小。对于矩阵范数，已知AX=B，可以将向量X变化为B，而矩阵范数就是来度量这个变化大小的。 L-P范数 L-P范数不是一个范数，而是一组范数。定义如下： $$L_p = \sqrt[p]{\sum_{i=1}^n x_i^p}, x=(x_1,x_2,…,x_n)$$ L0范数 上式中，当p=0时，就是L0范数。L0范数并不是一个真正的范数，它主要用来度量向量中非零元素的个数。L-0的定义为： $$||x|| = \sqrt[0]{\sum_1^n{x_i^0}},x=(x_1,x_2,…,x_n)$$ 其优化问题为： $$min||x||_0 \s.t. Ax=b$$ 在实际应用中，由于L0范数本身不容易有一个好的数学表示形式，给出上面问题的形式化表示是一个很难的问题，故被人认为是一个NP难问题。所以在实际情况中，L0的最优问题会被放宽到L1或L2下的最优化。 L-1范数 L1范数是我们经常见到的一种范数，它的定义如下： $$||x||_1=\sum_i{|x_i|}$$ 表示向量x中非零元素的绝对值之和。L1范数有许多别称，比如曼哈顿距离，最小绝对误差等等。使用L1范数可以度量两个向量间的差异，如绝对误差和（Sum of Absolute Difference）： $$SAD(x_1,x_2) = \sum_i{|x_{1i}-x_{2i}|}$$ 对于L1范数，他的优化问题如下： $$min||x||_1s.t. Ax = b$$ 由于L1范数的天然性质，对L1优化的解是一个稀疏解，因此L1范数也被叫做稀疏规则算子。通过L1可以实现特征的稀疏，去掉一些没有信息的特征，例如在对用户的电影爱好做分类的时候，用户有100个特征，可能只有十几个特征是对分类有用的，大部分特征如身高体重等可能都是无用的，利用L1范数就可以过滤掉。 L2范数 我们来度量欧式距离的就是一种L2范数，它的定义如下： $$||x||_2 = \sqrt{\sum_i{x_i^2}}$$ 表示向量元素的平方和再开平方。L2也可以用来度量两个向量之间的差异，如平方差和（Sum of Squared Difference）： $$SSD(x_1,x_2) = \sum_i{(x_{1i}-x_{2i})^2}$$ 对于L2范数，它的优化问题如下： $$min||x||_2s.t. Ax = b$$ L2范数通常会被用来做优化目标的正则化项，防止模型为了迎合训练集而过于复杂造成过拟合的情况，从而提高模型的泛化能力。 L-∞范数 当P=∞时，也就是L-∞范数，它主要被用来度量向量元素的最大值。用上面的L-P定义可以得到的L∞的定义为： $$||x||_∞ = \sqrt[∞]{\sum_1^n{x_i^∞}},x=(x_1,x_2,…,x_n)$$ 通常情况下，大家用的都是： $$||x||_∞ = max(|x_i|)$$ 来表示L-∞范数。]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My Notes Of Adversarial Attack]]></title>
    <url>%2F2017%2F10%2F18%2FMy-Notes-Of-Adversarial-Attack%2F</url>
    <content type="text"><![CDATA[摘要:对抗攻击简介正文: 一、对抗攻击简介对抗攻击是机器学习与计算机安全的结合（Intersection），是一个新兴的研究领域。以前设计的机器学习模型在面对攻击者精心设计的对抗攻击时往往会达不到预期的准确度，这种错误在如自动驾驶汽车等的实际应用中的影响是致命的。按照攻击者是否知道目的网络的结构参数，可以将对抗攻击分为白盒攻击和黑盒攻击。对抗攻击采取的形式，就是攻击者根据某种算法给原始输入数据加入人为难以分辨的微小扰动从而构成对抗样本。目的网络将对抗样本作为输入时，往往会输出错误的分类结果。实际中，根据目的网络最终得到的分类结果是否是攻击者预先设计好的，将对抗攻击分为目标攻击和非目标攻击。 研究对抗攻击的意义如下： 能让机器学习模型处理大规模数据； 以“计算机速度”处理攻击威胁； 不依赖数据的明显特征，发现实际应用中的各种内在威胁； 阻止已知和未知的恶意软件； 阻止恶意软件的提前执行； 优化模型，让分类模型达到更加高的分类准确率和更加低的错误率。我总结的对抗攻击方面的研究可以概括为下面几个方面：攻击原理探究、对抗攻击、对抗攻击防御、实际应用。 二、攻击原理对产生对抗攻击的原理的探究，目前主要有以下几个方面的观点： 《Intriguing properties of neural networks》提出：深度神经网络模型的非线性导致的输入与输出映射的不连续性，加上不充分的模型平均和不充分的正则化导致的过拟合使得对抗攻击成为可能。（It discovered was that several machine learning models, including state-of-the-art neural networks, are vulnerable to adversarial examples. That is, these machine learning models can misclassify examples that are only slightly different (imperceptibly so in many cases) from correctly classified examples drawn from the data distribution. In many cases, a wide variety of models with different architectures trained on different subsets of the training data misclassify the same adversarial example (this is kind of shocking). The implication is that adversarial examples expose fundamental problems in popular training algorithms.） 《Explaining And Harnessing Adversarial Examples》提出：高维空间中的线性就足以造成对抗样本，深度模型对对抗样本的脆弱性最主要的还是由于其线性部分的存在。通过将模型转变成非线性的RBF模型，就能减少神经网络模型对对抗攻击的脆弱性。(It shows that generic regularization strategies such as dropout, pre-training and model averaging or ensembling do not confer a significant reduction in a model’s vulnerability to adversarial examples. On the other hand, changing to nonlinear model families such as RBF networks can confer some resistance (to such adversarial examples).) 三、Adversarial Attack目前构建对抗样本的方法很多，总结如下： 传统的梯度下降、牛顿法、BFGS、L-BFGS：这些方法在2013年发表的文章《Evasion attacks against machine learning at test time》和2014年发表的文章《Intriguing properties of neural networks》中提到并运用来生成对抗样本，同时，这两篇文章也是最早提出对抗攻击这个概念的。前者用到的约束方式是传统的梯度下降法，同时约束目标上为了克服分类器函数的非凸性导致的局部最优解问题，提出给约束函数增加一个KDE（kernel density estimator）。 《Evasion attacks aginst machine learning at test time》这篇文章提出将KED部分放入到目标函数中，其作用类似于network intrusion detection(《Polymorphic blending attacks.》)，因此这个方法也可以算作是mimicry 攻击方法的一种。 《Intriguing properties of neural networks》 The authors estimated adversarial examples by solving penalized optimization problems and presented an analysis showing that the high complexity of neural networks might be a reason explaining the presence of adversarial examples. Unfortunately, the optimization method employed in this article is time-consuming and therefore does not scale to large datasets. FGSM：《Explaining And Harnessing Adversarial Examples》（2015.3） 这篇Goodfellow提出的FGSM方法，是比较经典的对抗样本生成方法。 这篇文章提出将KED部分放入到目标函数中，其作用类似于network intrusion detection(《Polymorphic blending attacks.》)，因此这个方法也可以算作是mimicry 攻击方法的一种。 缺点：Despite its efficiency, this method provides only a coarse approximation of the optimal perturbation vectors. In fact, it performs a unique gradient step, which often leads to sub-optimal solutions. Iterative version of FGSM（The Basic Iterative Method ）：《Adversarial examples in the physical world》（2017.2）这个方法可以视作是Fast Gradient Method的迭代应用。这篇文章针对上一篇FGSM方法的扰动规模比较大的缺陷，提出构造规模更加受限的对抗样本。 Jacobian saliency map attack (JSMA) ：《The limitations of deep learning in adversarial settings》（2015.10）这篇文章提出的对抗样本构建方法，是建立在攻击者已知目标网络的结构和参数等信息的情况下。这种方法的核心思想，是通过计算神经网络前向传播过程中的导数生成对抗样本。（Notes: This algorithm used the Jacobian matrix to determine which features to modify when generating adversarial examples. The Jacobian matrix based approach is also a kind of gradient based algorithm.） DeepFool：《Deepfool: a simple and accurate method to fool deep neural networks》（2015.10）这是第一个通过计算出最小的必要扰动，并应用到对抗样本构建的方法，使用的限制扰动规模的方法是L2范数。最终得到的对抗样本效果优于前面的FGSM和JSMA方法，但是这三者都需要比较大的计算资源。 Papernot Method：《 Adversarial perturbations against deep neural networks for malware classification》（2016.6）论文笔记：（https://www.zybuluo.com/wuxin1994/note/854417）这篇论文提到的对抗样本生成方法，更多的是针对于特定的应用场景——在输入是比较离散的数据情况下如何构建对抗样本。 Universal Perturbations： 《Universal adversarial perturbations》（2016.10）：这是一种对DeepFool方法的延伸。论文笔记：（https://www.zybuluo.com/wuxin1994/note/847422）（分析：Universal Perturbations is an untargeted attack that creates perturbations that can be applied to any image and is therefore useful as a black-box attack. Since this algorithm seeks the nearest class for misclassification, it is not easy to generate universal perturbations for targeted attacks.）《Analysis of universal adversarial perturbations》（2017.5） RP2： 《Robust Physical-World Attacks on Machine Learning Models》（2017.7）论文笔记：（https://www.zybuluo.com/wuxin1994/note/839621） CW（The Carlini and Wagner）：《Towards evaluating the robustness of neural networks》（2017.3）这篇文章的作者将Szegedy在《Explaining And Harnessing Adversarial Examples》提出的攻击方式转化成了一个更加高效的优化问题，能够以添加更小扰动的代价得到更加高效的对抗样本。(这篇文章是对《Explaining And Harnessing Adversarial Examples》的改进，能够用更小规模的扰动构造出效果更好的对抗样本，并且说明了distillation防御策略《Distillation as a defense to adversarial perturbations against deep neural networks》的不完备性) Virtual adversarial examples：《Virtual adversarial training: a regularization method for supervised and semi-supervised learning》（2017.4） 《Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN》(2017.2)论文笔记：（https://www.zybuluo.com/wuxin1994/note/867495） 《Machine Learning as an Adversarial Service: Learning Black-Box Adversarial Examples》（2017.8）论文笔记：(https://www.zybuluo.com/wuxin1994/note/860472) 《Towards Deep Learning Models Resistant to Adversarial Attacks》（2017.6）提到如何深入解释对抗样本的原理，如何构建universal的对抗样本。 四、Defence Policy对抗攻击的防御策略总结如下： Adversarial Training（augmenting the training data with perturbed examples）：《Intriguing properties of neural networks》（2014）所谓的对抗训练，就是防卫者通过自己构造对抗攻击，并且将人为增加扰动的对抗样本也加入到训练数据中，从而增强训练集，让训练后得到的模型更加稳定。（10.5新增）《Towards deep learning models resistant to adversarial attacks 》提到对抗训练用比较弱的攻击时，往往并没有增加模型对更强的攻击的鲁棒性。（这篇文章对对抗训练的方法提出了质疑，即是这种方法是否真的可以应对未来将要遇到的更强的攻击？） PCA whitening ：《Early methods for detecting adversarial images》（2016.8） Defensive distillation：《Distillation as a defense to adversarial perturbations against deep neural networks》（2016.3）这个方法通过两个步骤完成对模型稳定性的提升：第一步是训练分类模型，其最后一层的softmax层除以一个常数T；第二步是用同样的输入训练第二个模型，但是训练数据的标签不用原始标签，而是用第一步中训练的模型最后一层的概率向量作为最后softmax层的目标。《Extending Defensive Distillation》（2017.5）《Towards evaluating the robustness of neural networks》中推翻了这个防御策略，说明他效果不怎么好。 Feature squeezing：《Feature squeezing: Detecting adversarial examples in deep neural networks》（2017.4）《Feature squeezing mitigates and detects carlini/wagner adversarial examples》（2017.5） Detection systems: （这种defence方法采取的策略是在目的网络模型前面增加一个额外的探测系统，判断输入是否是经过人为扰动的对抗样本）Performe statistical tests:《On the (statistical) detection of adversarial examples》（2017.2）Use an additional model for detection:《Adversarial and clean data are not twins》（2017.4）《On detecting adversarial perturbations》（2017.2）Apply dropout at test time:《Detecting adversarial samples from artifacts》（2017.3） Generative Adversarial Networks (GAN):《Generative Adversarial Trainer Defense to Adversarial Perturbations with GAN》（2017.5）《AE-GAN: adversarial eliminating with GAN》（2017.7）论文笔记：（https://www.zybuluo.com/wuxin1994/note/881171） 《Efficient Defenses Against Adversarial Attacks》（2017.7）论文笔记：(https://www.zybuluo.com/wuxin1994/note/863551) 五、其他研究对抗攻击可移植性研究：《Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples》（2016.5）论文笔记：(https://www.zybuluo.com/wuxin1994/note/850755) 《The space of transferable adversarial examples》（Florian Tramèr, Nicolas Papernot, Ian J. Goodfellow, Dan Boneh, and Patrick D. McDaniel.The space of transferable adversarial examples. arXiv preprint arXiv:1704.03453, 2017.）：propose a linear algebraic notion of adversarial subspaces. 《Towards Deep Learning Models Resistant to Adversarial Attacks》里面对可移植性也有一些研究：we find that larger model capacity and adversarial training reduces the transferability of adversarial examples） 六、实际应用对抗攻击在实际中的应用： 面部识别：《Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition》（2016.10） 实际拍照图片：《Adversarial examples in the physical world》（2017.2）这篇文章是在实际应用中，对抗攻击往往不能将数字化的对抗样本作为目的分类器的输入，只能将对抗样本打印到纸张上，然后用拍照之类的方式得到目的网络的输入时，人为添加的扰动比较小，在拍照过程中产生了失真，不能达到攻击目的。 路标：《Robust Physical-World Attacks on Machine Learning Models》（2017.7）论文笔记：(https://www.zybuluo.com/wuxin1994/note/839621) 自动汽车：《Concrete Problems for Autonomous Vehicle Safety: Advantages of Bayesian Deep Learning》（2017）论文笔记：(https://www.zybuluo.com/wuxin1994/note/843327) 恶意软件分类：《Adversarial Perturbations Against Deep Neural Networks for Malware Classification》（2016.6）论文笔记：(https://www.zybuluo.com/wuxin1994/note/854417)《Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN》（2017.5）论文笔记：（https://www.zybuluo.com/wuxin1994/note/867495） 七、总结根据目前学习的对抗攻击研究，我觉得以后的研究方向主要有以下几个方面： 效率更高的对抗样本构造方法； 更好的Defence策略构建； 根据特定的应用场景探究攻击和防御策略（垃圾邮件分类、恶意软件识别、人脸识别等与安全相关的领域）； 得到对抗样本，在模型的训练集中加入对抗攻击样本，可以增强神经网络的鲁棒性； 理解对抗攻击背后的数学原理，实际就是探索深度网络的原理，尝试打开这个黑盒子。 （9.18更新）已经知道了根据对目的模型的了解程度可以造成不同的影响结果，那么能否根据这一点来探究各个影响因素分别的效果呢？ （10.4更新）存在这样一个问题：很难去评判一个defence方法是否是足够有效的，也很难去评价一个攻击方法是否是足够成功的。因为往往在对抗攻击研究进程中，一个提出的defence策略总是会被后来提出的攻击方法证明是不够鲁棒的。反之，一个攻击方法也往往会被后面提出的defence方法证明是无效的。这种往复的循环博弈，给研究指出了一个新的方向:可以研究一种评估攻击方法或者防御策略的有效性的评估方法。这一部分参考《Ground-Truth Adversarial Examples》：a defensive technique that was at first thought to produce robust networks was later shown to be susceptible to new kinds of attacks. 最近将GAN与对抗攻击研究相结合的方向让我很感兴趣。它可以同时构建效果更加好的对抗样本和实现让模型更加鲁棒的defence策略。因为在我看来，对抗攻击可以实现，其本质一方面是因为神经网络乃至深度学习可以实现分类和预测目的的原理还比较模糊，因此可以利用这种不确定性来混淆模型；另一方面是因为数据本身就不能按照抽取的特征得到固定的分类结果，每一个个体具有比较大的误差因素。因此，模型容易受到对抗攻击是因为模型的泛化能力不够，在处理非训练数据时容易得到错误的结果。提高模型的泛化能力才是最好的defence策略。而最近特别火的GAN网络正是一种提高网络泛化能力的手段，在多个方面都被证明能让训练得到的模型具有更好的效果。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>adversarial attack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python去掉文章中所有的符号]]></title>
    <url>%2F2017%2F01%2F05%2FPython%E5%8C%B9%E9%85%8D%E6%89%80%E6%9C%89%E7%AC%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[如何去掉一个字符串中所有的符号 使用python中的正则相关的库：1import re 然后用写出对应的正则表达式：1r = &quot;[+\.\!\/_,$%^*(+\&quot;\&apos;]+|[+——！，。？?、~@《￥》\&#123;\&#125;#￥%…“•”…&amp;*（）\n\t\s]+&quot; 接着用替换1re.sub(r,&apos;&apos;,&quot;nishog.;dfs$fd*&quot;)]]></content>
      <categories>
        <category>Languages</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
</search>
